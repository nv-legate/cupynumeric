

<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Advanced Topics in cuPyNumeric (Profiling &amp; Debugging) &#8212; NVIDIA cuPyNumeric (26.03.00.dev+1.g4464f6f7)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/nvidia-sphinx-theme.css?v=933278ad" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/params.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />



    <script src="../_static/documentation_options.js?v=66a87e93"></script>
    <script src="../_static/doctools.js?v=fd6eb6e6"></script>
    <script src="../_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=4ea706d9"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'user/profiling_debugging';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://docs.nvidia.com/cupynumeric/switcher.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '26.03';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            true;
        </script>

    <link rel="icon" href="../_static/favicon.png"/>

    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />


<script src="https://assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js"></script>


  </head>

  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>


  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="NVIDIA cuPyNumeric (26.03.00.dev+1.g4464f6f7) - Home"/>
    <img src="../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="NVIDIA cuPyNumeric (26.03.00.dev+1.g4464f6f7) - Home"/>
  
  
    <p class="title logo__title">NVIDIA cuPyNumeric (26.03.00.dev+1.g4464f6f7)</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        



  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="NVIDIA cuPyNumeric (26.03.00.dev+1.g4464f6f7) - Home"/>
    <img src="../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="NVIDIA cuPyNumeric (26.03.00.dev+1.g4464f6f7) - Home"/>
  
  
    <p class="title logo__title">NVIDIA cuPyNumeric (26.03.00.dev+1.g4464f6f7)</p>
  
</a>


  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">



<nav class="bd-docs-nav bd-links"
     aria-label="Table of Contents">
  <p class="bd-links__title" role="heading" aria-level="1">Table of Contents</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="index.html">User guide</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html">Best practices</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="howtos/index.html">Howtos</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="howtos/measuring.html">Measure API coverage</a></li>
<li class="toctree-l3"><a class="reference internal" href="howtos/benchmarking.html">Performance Benchmarking</a></li>
<li class="toctree-l3"><a class="reference internal" href="howtos/patching.html">Trying Numpy code without changes</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="advanced.html">Advanced topics</a></li>
<li class="toctree-l2"><a class="reference internal" href="differences.html">Differences with Numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial.html">Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="task.html">Extend cuPyNumeric with Legate-tasks</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../examples/index.html">Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples/black_scholes.html">Black-Scholes options pricing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/cholesky.html">Cholesky decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/stencil.html">Jacobi stencil</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/kmeans.html">K-Means Clustering Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/edge_detection.html">Edge Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/newton_raphson_2d.html">Newton Raphson Method In Two Dimensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/compact_finite_difference.html">Compact Finite Difference Scheme</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/torchswe.html">TorchSWE case study</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/classes.html">Classes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/broadcast.html">cupynumeric.broadcast</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/ndarray.html">The N-Dimensional array (<code class="xref py py-class docutils literal notranslate"><span class="pre">cupynumeric.ndarray</span></code>)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/_ndarray.html">cupynumeric.ndarray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.all.html">cupynumeric.ndarray.all</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.any.html">cupynumeric.ndarray.any</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.flags.html">cupynumeric.ndarray.flags</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.shape.html">cupynumeric.ndarray.shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.strides.html">cupynumeric.ndarray.strides</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.ndim.html">cupynumeric.ndarray.ndim</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.data.html">cupynumeric.ndarray.data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.size.html">cupynumeric.ndarray.size</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.itemsize.html">cupynumeric.ndarray.itemsize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.nbytes.html">cupynumeric.ndarray.nbytes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.base.html">cupynumeric.ndarray.base</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.ctypes.html">cupynumeric.ndarray.ctypes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.dtype.html">cupynumeric.ndarray.dtype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.T.html">cupynumeric.ndarray.T</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.real.html">cupynumeric.ndarray.real</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.imag.html">cupynumeric.ndarray.imag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.flat.html">cupynumeric.ndarray.flat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.item.html">cupynumeric.ndarray.item</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.tolist.html">cupynumeric.ndarray.tolist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.itemset.html">cupynumeric.ndarray.itemset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.tostring.html">cupynumeric.ndarray.tostring</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.tobytes.html">cupynumeric.ndarray.tobytes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.tofile.html">cupynumeric.ndarray.tofile</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.dump.html">cupynumeric.ndarray.dump</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.dumps.html">cupynumeric.ndarray.dumps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.astype.html">cupynumeric.ndarray.astype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.copy.html">cupynumeric.ndarray.copy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.view.html">cupynumeric.ndarray.view</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.getfield.html">cupynumeric.ndarray.getfield</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.setfield.html">cupynumeric.ndarray.setfield</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.setflags.html">cupynumeric.ndarray.setflags</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.fill.html">cupynumeric.ndarray.fill</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.reshape.html">cupynumeric.ndarray.reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.transpose.html">cupynumeric.ndarray.transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.swapaxes.html">cupynumeric.ndarray.swapaxes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.flatten.html">cupynumeric.ndarray.flatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.ravel.html">cupynumeric.ndarray.ravel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.squeeze.html">cupynumeric.ndarray.squeeze</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.take.html">cupynumeric.ndarray.take</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.put.html">cupynumeric.ndarray.put</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.choose.html">cupynumeric.ndarray.choose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.sort.html">cupynumeric.ndarray.sort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.argsort.html">cupynumeric.ndarray.argsort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.partition.html">cupynumeric.ndarray.partition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.argpartition.html">cupynumeric.ndarray.argpartition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.searchsorted.html">cupynumeric.ndarray.searchsorted</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.nonzero.html">cupynumeric.ndarray.nonzero</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.compress.html">cupynumeric.ndarray.compress</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.diagonal.html">cupynumeric.ndarray.diagonal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.trace.html">cupynumeric.ndarray.trace</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.max.html">cupynumeric.ndarray.max</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.argmax.html">cupynumeric.ndarray.argmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.min.html">cupynumeric.ndarray.min</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.argmin.html">cupynumeric.ndarray.argmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.clip.html">cupynumeric.ndarray.clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.conj.html">cupynumeric.ndarray.conj</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.conjugate.html">cupynumeric.ndarray.conjugate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.dot.html">cupynumeric.ndarray.dot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.flip.html">cupynumeric.ndarray.flip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.round.html">cupynumeric.ndarray.round</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.sum.html">cupynumeric.ndarray.sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.cumsum.html">cupynumeric.ndarray.cumsum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.mean.html">cupynumeric.ndarray.mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.var.html">cupynumeric.ndarray.var</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.prod.html">cupynumeric.ndarray.prod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.cumprod.html">cupynumeric.ndarray.cumprod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.all.html">cupynumeric.ndarray.all</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.any.html">cupynumeric.ndarray.any</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.unique.html">cupynumeric.ndarray.unique</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__lt__.html">cupynumeric.ndarray.__lt__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__le__.html">cupynumeric.ndarray.__le__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__gt__.html">cupynumeric.ndarray.__gt__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__ge__.html">cupynumeric.ndarray.__ge__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__eq__.html">cupynumeric.ndarray.__eq__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__ne__.html">cupynumeric.ndarray.__ne__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__bool__.html">cupynumeric.ndarray.__bool__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__neg__.html">cupynumeric.ndarray.__neg__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__pos__.html">cupynumeric.ndarray.__pos__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__abs__.html">cupynumeric.ndarray.__abs__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__invert__.html">cupynumeric.ndarray.__invert__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__add__.html">cupynumeric.ndarray.__add__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__sub__.html">cupynumeric.ndarray.__sub__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__mul__.html">cupynumeric.ndarray.__mul__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__truediv__.html">cupynumeric.ndarray.__truediv__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__floordiv__.html">cupynumeric.ndarray.__floordiv__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__mod__.html">cupynumeric.ndarray.__mod__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__divmod__.html">cupynumeric.ndarray.__divmod__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__pow__.html">cupynumeric.ndarray.__pow__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__lshift__.html">cupynumeric.ndarray.__lshift__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__rshift__.html">cupynumeric.ndarray.__rshift__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__and__.html">cupynumeric.ndarray.__and__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__or__.html">cupynumeric.ndarray.__or__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__xor__.html">cupynumeric.ndarray.__xor__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__iadd__.html">cupynumeric.ndarray.__iadd__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__isub__.html">cupynumeric.ndarray.__isub__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__imul__.html">cupynumeric.ndarray.__imul__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__itruediv__.html">cupynumeric.ndarray.__itruediv__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__ifloordiv__.html">cupynumeric.ndarray.__ifloordiv__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__imod__.html">cupynumeric.ndarray.__imod__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__ipow__.html">cupynumeric.ndarray.__ipow__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__ilshift__.html">cupynumeric.ndarray.__ilshift__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__irshift__.html">cupynumeric.ndarray.__irshift__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__iand__.html">cupynumeric.ndarray.__iand__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__ior__.html">cupynumeric.ndarray.__ior__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__ixor__.html">cupynumeric.ndarray.__ixor__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__matmul__.html">cupynumeric.ndarray.__matmul__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__imatmul__.html">cupynumeric.ndarray.__imatmul__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__rmatmul__.html">cupynumeric.ndarray.__rmatmul__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__copy__.html">cupynumeric.ndarray.__copy__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__deepcopy__.html">cupynumeric.ndarray.__deepcopy__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__index__.html">cupynumeric.ndarray.__index__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__reduce__.html">cupynumeric.ndarray.__reduce__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__setstate__.html">cupynumeric.ndarray.__setstate__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__new__.html">cupynumeric.ndarray.__new__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__array__.html">cupynumeric.ndarray.__array__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__len__.html">cupynumeric.ndarray.__len__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__getitem__.html">cupynumeric.ndarray.__getitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__setitem__.html">cupynumeric.ndarray.__setitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__contains__.html">cupynumeric.ndarray.__contains__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__int__.html">cupynumeric.ndarray.__int__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__float__.html">cupynumeric.ndarray.__float__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__complex__.html">cupynumeric.ndarray.__complex__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__str__.html">cupynumeric.ndarray.__str__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.__repr__.html">cupynumeric.ndarray.__repr__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndarray.stencil_hint.html">cupynumeric.ndarray.stencil_hint</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/routines.html">Routines</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/creation.html">Array creation routines</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.empty.html">cupynumeric.empty</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.empty_like.html">cupynumeric.empty_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.eye.html">cupynumeric.eye</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.identity.html">cupynumeric.identity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ones.html">cupynumeric.ones</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ones_like.html">cupynumeric.ones_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.zeros.html">cupynumeric.zeros</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.zeros_like.html">cupynumeric.zeros_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.full.html">cupynumeric.full</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.full_like.html">cupynumeric.full_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.array.html">cupynumeric.array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.asarray.html">cupynumeric.asarray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.copy.html">cupynumeric.copy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.copyto.html">cupynumeric.copyto</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.repeat.html">cupynumeric.repeat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.arange.html">cupynumeric.arange</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.logspace.html">cupynumeric.logspace</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.linspace.html">cupynumeric.linspace</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.meshgrid.html">cupynumeric.meshgrid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.diag.html">cupynumeric.diag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.diagflat.html">cupynumeric.diagflat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.tri.html">cupynumeric.tri</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.tril.html">cupynumeric.tril</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.triu.html">cupynumeric.triu</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/manipulation.html">Array manipulation routines</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ndim.html">cupynumeric.ndim</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.shape.html">cupynumeric.shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.reshape.html">cupynumeric.reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ravel.html">cupynumeric.ravel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.moveaxis.html">cupynumeric.moveaxis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.swapaxes.html">cupynumeric.swapaxes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.transpose.html">cupynumeric.transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.atleast_1d.html">cupynumeric.atleast_1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.atleast_2d.html">cupynumeric.atleast_2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.atleast_3d.html">cupynumeric.atleast_3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.broadcast_arrays.html">cupynumeric.broadcast_arrays</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.broadcast_shapes.html">cupynumeric.broadcast_shapes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.broadcast_to.html">cupynumeric.broadcast_to</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.expand_dims.html">cupynumeric.expand_dims</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.squeeze.html">cupynumeric.squeeze</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.asarray.html">cupynumeric.asarray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.append.html">cupynumeric.append</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.concatenate.html">cupynumeric.concatenate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.insert.html">cupynumeric.insert</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.stack.html">cupynumeric.stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.block.html">cupynumeric.block</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.vstack.html">cupynumeric.vstack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.hstack.html">cupynumeric.hstack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.dstack.html">cupynumeric.dstack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.column_stack.html">cupynumeric.column_stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.row_stack.html">cupynumeric.row_stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.split.html">cupynumeric.split</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.array_split.html">cupynumeric.array_split</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.dsplit.html">cupynumeric.dsplit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.hsplit.html">cupynumeric.hsplit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.vsplit.html">cupynumeric.vsplit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.tile.html">cupynumeric.tile</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.flip.html">cupynumeric.flip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fliplr.html">cupynumeric.fliplr</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.flipud.html">cupynumeric.flipud</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.roll.html">cupynumeric.roll</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.rot90.html">cupynumeric.rot90</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.delete.html">cupynumeric.delete</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/binary.html">Binary operations</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.bitwise_and.html">cupynumeric.bitwise_and</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.bitwise_or.html">cupynumeric.bitwise_or</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.bitwise_xor.html">cupynumeric.bitwise_xor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.invert.html">cupynumeric.invert</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.left_shift.html">cupynumeric.left_shift</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.right_shift.html">cupynumeric.right_shift</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.packbits.html">cupynumeric.packbits</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.unpackbits.html">cupynumeric.unpackbits</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/datatype.html">Data type routines</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.find_common_type.html">cupynumeric.find_common_type</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/indexing.html">Indexing routines</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.unravel_index.html">cupynumeric.unravel_index</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.diag_indices.html">cupynumeric.diag_indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.diag_indices_from.html">cupynumeric.diag_indices_from</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.mask_indices.html">cupynumeric.mask_indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.tril_indices.html">cupynumeric.tril_indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.tril_indices_from.html">cupynumeric.tril_indices_from</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.triu_indices.html">cupynumeric.triu_indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.triu_indices_from.html">cupynumeric.triu_indices_from</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.indices.html">cupynumeric.indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ix_.html">cupynumeric.ix_</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nonzero.html">cupynumeric.nonzero</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.flatnonzero.html">cupynumeric.flatnonzero</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.where.html">cupynumeric.where</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ravel_multi_index.html">cupynumeric.ravel_multi_index</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.choose.html">cupynumeric.choose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.compress.html">cupynumeric.compress</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.diag.html">cupynumeric.diag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.diagonal.html">cupynumeric.diagonal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.select.html">cupynumeric.select</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.take.html">cupynumeric.take</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.take_along_axis.html">cupynumeric.take_along_axis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fill_diagonal.html">cupynumeric.fill_diagonal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.put.html">cupynumeric.put</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.putmask.html">cupynumeric.putmask</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.put_along_axis.html">cupynumeric.put_along_axis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.place.html">cupynumeric.place</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/io.html">Input and output</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.load.html">cupynumeric.load</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/linalg.html">Linear algebra (<code class="xref py py-mod docutils literal notranslate"><span class="pre">cupynumeric.linalg</span></code>)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.dot.html">cupynumeric.dot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.vdot.html">cupynumeric.vdot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.inner.html">cupynumeric.inner</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.outer.html">cupynumeric.outer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.matmul.html">cupynumeric.matmul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.tensordot.html">cupynumeric.tensordot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.einsum.html">cupynumeric.einsum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.einsum_path.html">cupynumeric.einsum_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.linalg.matrix_power.html">cupynumeric.linalg.matrix_power</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.linalg.multi_dot.html">cupynumeric.linalg.multi_dot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.linalg.cholesky.html">cupynumeric.linalg.cholesky</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.linalg.eig.html">cupynumeric.linalg.eig</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.linalg.eigh.html">cupynumeric.linalg.eigh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.linalg.eigvals.html">cupynumeric.linalg.eigvals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.linalg.eigvalsh.html">cupynumeric.linalg.eigvalsh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.linalg.qr.html">cupynumeric.linalg.qr</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.linalg.svd.html">cupynumeric.linalg.svd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.linalg.norm.html">cupynumeric.linalg.norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.trace.html">cupynumeric.trace</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.linalg.solve.html">cupynumeric.linalg.solve</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.linalg.pinv.html">cupynumeric.linalg.pinv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.linalg.expm.html">cupynumeric.linalg.expm</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/logic.html">Logic functions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.all.html">cupynumeric.all</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.any.html">cupynumeric.any</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.isfinite.html">cupynumeric.isfinite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.isinf.html">cupynumeric.isinf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.isnan.html">cupynumeric.isnan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.isneginf.html">cupynumeric.isneginf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.isposinf.html">cupynumeric.isposinf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.iscomplex.html">cupynumeric.iscomplex</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.iscomplexobj.html">cupynumeric.iscomplexobj</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.isreal.html">cupynumeric.isreal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.isrealobj.html">cupynumeric.isrealobj</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.isscalar.html">cupynumeric.isscalar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.logical_and.html">cupynumeric.logical_and</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.logical_or.html">cupynumeric.logical_or</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.logical_not.html">cupynumeric.logical_not</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.logical_xor.html">cupynumeric.logical_xor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.allclose.html">cupynumeric.allclose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.isclose.html">cupynumeric.isclose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.array_equal.html">cupynumeric.array_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.greater.html">cupynumeric.greater</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.greater_equal.html">cupynumeric.greater_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.less.html">cupynumeric.less</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.less_equal.html">cupynumeric.less_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.equal.html">cupynumeric.equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.not_equal.html">cupynumeric.not_equal</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/math.html">Mathematical functions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.sin.html">cupynumeric.sin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.cos.html">cupynumeric.cos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.tan.html">cupynumeric.tan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.arcsin.html">cupynumeric.arcsin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.arccos.html">cupynumeric.arccos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.arctan.html">cupynumeric.arctan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.hypot.html">cupynumeric.hypot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.arctan2.html">cupynumeric.arctan2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.degrees.html">cupynumeric.degrees</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.radians.html">cupynumeric.radians</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.deg2rad.html">cupynumeric.deg2rad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.rad2deg.html">cupynumeric.rad2deg</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.sinh.html">cupynumeric.sinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.cosh.html">cupynumeric.cosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.tanh.html">cupynumeric.tanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.arcsinh.html">cupynumeric.arcsinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.arccosh.html">cupynumeric.arccosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.arctanh.html">cupynumeric.arctanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.round.html">cupynumeric.round</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.rint.html">cupynumeric.rint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.floor.html">cupynumeric.floor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ceil.html">cupynumeric.ceil</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.trunc.html">cupynumeric.trunc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.prod.html">cupynumeric.prod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.sum.html">cupynumeric.sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.cumprod.html">cupynumeric.cumprod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.cumsum.html">cupynumeric.cumsum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.diff.html">cupynumeric.diff</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nancumprod.html">cupynumeric.nancumprod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nancumsum.html">cupynumeric.nancumsum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nanprod.html">cupynumeric.nanprod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nansum.html">cupynumeric.nansum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.gradient.html">cupynumeric.gradient</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.cross.html">cupynumeric.cross</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.exp.html">cupynumeric.exp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.expm1.html">cupynumeric.expm1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.exp2.html">cupynumeric.exp2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.log.html">cupynumeric.log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.log10.html">cupynumeric.log10</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.log2.html">cupynumeric.log2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.log1p.html">cupynumeric.log1p</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.logaddexp.html">cupynumeric.logaddexp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.logaddexp2.html">cupynumeric.logaddexp2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.signbit.html">cupynumeric.signbit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.copysign.html">cupynumeric.copysign</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.frexp.html">cupynumeric.frexp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.ldexp.html">cupynumeric.ldexp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nextafter.html">cupynumeric.nextafter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.lcm.html">cupynumeric.lcm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.gcd.html">cupynumeric.gcd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.add.html">cupynumeric.add</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.reciprocal.html">cupynumeric.reciprocal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.positive.html">cupynumeric.positive</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.negative.html">cupynumeric.negative</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.multiply.html">cupynumeric.multiply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.divide.html">cupynumeric.divide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.power.html">cupynumeric.power</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.subtract.html">cupynumeric.subtract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.true_divide.html">cupynumeric.true_divide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.floor_divide.html">cupynumeric.floor_divide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.float_power.html">cupynumeric.float_power</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fmod.html">cupynumeric.fmod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.mod.html">cupynumeric.mod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.modf.html">cupynumeric.modf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.remainder.html">cupynumeric.remainder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.real.html">cupynumeric.real</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.real_if_close.html">cupynumeric.real_if_close</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.imag.html">cupynumeric.imag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.angle.html">cupynumeric.angle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.conj.html">cupynumeric.conj</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.conjugate.html">cupynumeric.conjugate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.maximum.html">cupynumeric.maximum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fmax.html">cupynumeric.fmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.amax.html">cupynumeric.amax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.minimum.html">cupynumeric.minimum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fmin.html">cupynumeric.fmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.amin.html">cupynumeric.amin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nanmin.html">cupynumeric.nanmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nanmax.html">cupynumeric.nanmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.convolve.html">cupynumeric.convolve</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.clip.html">cupynumeric.clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nan_to_num.html">cupynumeric.nan_to_num</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.sqrt.html">cupynumeric.sqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.cbrt.html">cupynumeric.cbrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.square.html">cupynumeric.square</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.roots.html">cupynumeric.roots</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.absolute.html">cupynumeric.absolute</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fabs.html">cupynumeric.fabs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.sign.html">cupynumeric.sign</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.inner.html">cupynumeric.inner</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.outer.html">cupynumeric.outer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.vdot.html">cupynumeric.vdot</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/fft.html">Discrete Fourier Transform (<code class="xref py py-mod docutils literal notranslate"><span class="pre">cupynumeric.fft</span></code>)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.fft.html">cupynumeric.fft.fft</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.ifft.html">cupynumeric.fft.ifft</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.fft2.html">cupynumeric.fft.fft2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.ifft2.html">cupynumeric.fft.ifft2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.fftn.html">cupynumeric.fft.fftn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.ifftn.html">cupynumeric.fft.ifftn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.rfft.html">cupynumeric.fft.rfft</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.irfft.html">cupynumeric.fft.irfft</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.rfft2.html">cupynumeric.fft.rfft2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.irfft2.html">cupynumeric.fft.irfft2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.rfftn.html">cupynumeric.fft.rfftn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.irfftn.html">cupynumeric.fft.irfftn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.hfft.html">cupynumeric.fft.hfft</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.ihfft.html">cupynumeric.fft.ihfft</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.fftshift.html">cupynumeric.fft.fftshift</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.fft.ifftshift.html">cupynumeric.fft.ifftshift</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/random.html">Random sampling (<code class="xref py py-mod docutils literal notranslate"><span class="pre">cupynumeric.random</span></code>)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.default_rng.html">cupynumeric.random.default_rng</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/_generator.html">cupynumeric.random.Generator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/_bitgenerator.html">cupynumeric.random.BitGenerator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.seed.html">cupynumeric.random.seed</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.default_rng.html">cupynumeric.random.default_rng</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.rand.html">cupynumeric.random.rand</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.randn.html">cupynumeric.random.randn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.randint.html">cupynumeric.random.randint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.random.html">cupynumeric.random.random</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.random_integers.html">cupynumeric.random.random_integers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.random_sample.html">cupynumeric.random.random_sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.bytes.html">cupynumeric.random.bytes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.beta.html">cupynumeric.random.beta</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.binomial.html">cupynumeric.random.binomial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.chisquare.html">cupynumeric.random.chisquare</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.exponential.html">cupynumeric.random.exponential</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.f.html">cupynumeric.random.f</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.gamma.html">cupynumeric.random.gamma</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.geometric.html">cupynumeric.random.geometric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.gumbel.html">cupynumeric.random.gumbel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.hypergeometric.html">cupynumeric.random.hypergeometric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.laplace.html">cupynumeric.random.laplace</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.logistic.html">cupynumeric.random.logistic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.lognormal.html">cupynumeric.random.lognormal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.logseries.html">cupynumeric.random.logseries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.negative_binomial.html">cupynumeric.random.negative_binomial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.noncentral_chisquare.html">cupynumeric.random.noncentral_chisquare</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.noncentral_f.html">cupynumeric.random.noncentral_f</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.normal.html">cupynumeric.random.normal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.pareto.html">cupynumeric.random.pareto</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.poisson.html">cupynumeric.random.poisson</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.power.html">cupynumeric.random.power</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.ranf.html">cupynumeric.random.ranf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.rayleigh.html">cupynumeric.random.rayleigh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.sample.html">cupynumeric.random.sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.standard_cauchy.html">cupynumeric.random.standard_cauchy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.standard_exponential.html">cupynumeric.random.standard_exponential</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.standard_gamma.html">cupynumeric.random.standard_gamma</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.standard_t.html">cupynumeric.random.standard_t</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.triangular.html">cupynumeric.random.triangular</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.uniform.html">cupynumeric.random.uniform</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.vonmises.html">cupynumeric.random.vonmises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.wald.html">cupynumeric.random.wald</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.weibull.html">cupynumeric.random.weibull</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.random.zipf.html">cupynumeric.random.zipf</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/set.html">Set routines</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.unique.html">cupynumeric.unique</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.in1d.html">cupynumeric.in1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.isin.html">cupynumeric.isin</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/sorting.html">Sorting, searching, and counting</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.argpartition.html">cupynumeric.argpartition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.argsort.html">cupynumeric.argsort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.partition.html">cupynumeric.partition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.sort.html">cupynumeric.sort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.sort_complex.html">cupynumeric.sort_complex</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.argmax.html">cupynumeric.argmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.argmin.html">cupynumeric.argmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.argwhere.html">cupynumeric.argwhere</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.flatnonzero.html">cupynumeric.flatnonzero</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nanargmax.html">cupynumeric.nanargmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nanargmin.html">cupynumeric.nanargmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nonzero.html">cupynumeric.nonzero</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.searchsorted.html">cupynumeric.searchsorted</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.extract.html">cupynumeric.extract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.where.html">cupynumeric.where</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.count_nonzero.html">cupynumeric.count_nonzero</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/statistics.html">Statistics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.quantile.html">cupynumeric.quantile</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.percentile.html">cupynumeric.percentile</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nanquantile.html">cupynumeric.nanquantile</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nanpercentile.html">cupynumeric.nanpercentile</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.average.html">cupynumeric.average</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.mean.html">cupynumeric.mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nanmean.html">cupynumeric.nanmean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.var.html">cupynumeric.var</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.median.html">cupynumeric.median</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.nanmedian.html">cupynumeric.nanmedian</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.cov.html">cupynumeric.cov</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.bincount.html">cupynumeric.bincount</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.histogram.html">cupynumeric.histogram</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.histogram2d.html">cupynumeric.histogram2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.histogramdd.html">cupynumeric.histogramdd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.digitize.html">cupynumeric.digitize</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/window.html">Window functions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.bartlett.html">cupynumeric.bartlett</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.blackman.html">cupynumeric.blackman</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.hamming.html">cupynumeric.hamming</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.hanning.html">cupynumeric.hanning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/generated/cupynumeric.kaiser.html">cupynumeric.kaiser</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../api/settings.html">Settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/comparison.html">Project comparisons</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../faqs.html">Frequently Asked Questions</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../developer/index.html">Developer guide</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../developer/CONTRIBUTING.html">Contributing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developer/building.html">Building from source</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developer/testing.html">Running tests</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../acknowledgments.html">Acknowledgments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../oss-licenses.html">Third-party notices</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>



      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Advanced Topics in cuPyNumeric (Profiling &amp; Debugging)</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="advanced-topics-in-cupynumeric-profiling-debugging">
<span id="advanced-profiling-debugging"></span><h1>Advanced Topics in cuPyNumeric (Profiling &amp; Debugging)<a class="headerlink" href="#advanced-topics-in-cupynumeric-profiling-debugging" title="Link to this heading">#</a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h2>
<p>This section assumes familiarity with running cuPyNumeric, extending it with
Legate Task, and scaling gradient boosting with Legate Boost. For a refresher,
see:</p>
<ul class="simple">
<li><p>Setting up your environment and running  <a class="reference external" href="https://docs.nvidia.com/cupynumeric/latest/user/tutorial.html">cuPyNumeric</a></p></li>
<li><p>Extending cuPyNumeric with <a class="reference external" href="https://docs.nvidia.com/cupynumeric/latest/user/task.html">Legate Task</a></p></li>
<li><p>Scaling gradient boosting with <strong>Legate Boost</strong></p></li>
</ul>
<p>cuPyNumeric scales familiar NumPy workloads seamlessly across CPUs, GPUs, and
multi-node clusters. Previous sections covered how to get code running; here
the focus shifts to making workloads production-ready. This includes finding
bottlenecks, managing memory effectively, and preventing failures before
they disrupt a job. This section focuses on two advanced capabilities in cuPyNumeric and the
Legate runtime that address these challenges:</p>
<ul class="simple">
<li><p><strong>Profiling cuPyNumeric applications</strong>  to tune performance and analyze
scalability. Profiling reveals bottlenecks such as idle GPUs,
synchronization delays, or overly fine-grained tasks, helping you restructure
code for better scaling.</p></li>
<li><p><strong>Debugging and Out-of-Memory (OOM) strategies</strong>  to improve reliability
in memory-intensive workloads. These tools help diagnose crashes, manage
GPU/CPU memory effectively, and prevent common anti-patterns so applications
remain robust under heavy loads.</p></li>
</ul>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 100.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>What youll gain:</strong> By combining profiling with practical OOM-handling strategies,
you can improve efficiency and scaling by identifying memory pressure and over-granular
execution, while reducing OOM crashes and runtime stalls across CPUs, GPUs, and multi-node
systems.</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>For more detail, see the official references:</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.nvidia.com/cupynumeric/latest/index.html">cuPyNumeric Documentation</a></p></li>
<li><p><a class="reference external" href="https://docs.nvidia.com/legate/latest/index.html">Legate Documentation</a></p></li>
</ul>
</section>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Link to this heading">#</a></h2>
<p><strong>1.) To install the built-in Legate profiler tool in your Conda environment, run:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>install<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>-c<span class="w"> </span>legate<span class="w"> </span>legate-profiler
</pre></div>
</div>
<p><strong>2.) After installing the Legate profiler (legate-profiler), profile the code
using the ``profile`` flag:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># CPU example</span>
legate<span class="w"> </span>--cpus<span class="w"> </span><span class="m">8</span><span class="w"> </span>--sysmem<span class="w"> </span><span class="m">4000</span><span class="w"> </span>--profile<span class="w"> </span>myprog.py

<span class="c1"># Single GPU example</span>
legate<span class="w"> </span>--gpus<span class="w"> </span><span class="m">1</span><span class="w"> </span>--profile<span class="w"> </span>myprog.py

<span class="c1"># Multi-GPU example (single node, multi-rank: 4 ranks  1 GPU)</span>
srun<span class="w"> </span>-n<span class="w"> </span><span class="m">4</span><span class="w"> </span>--mpi<span class="o">=</span>pmix<span class="w"> </span>legate<span class="w"> </span>--gpus<span class="w"> </span><span class="m">1</span><span class="w"> </span>--profile<span class="w"> </span>myprog.py

<span class="c1"># Multi-node example (2 nodes  4 GPUs = 8 ranks  1 GPU)</span>
srun<span class="w"> </span>-N<span class="w"> </span><span class="m">2</span><span class="w"> </span>--ntasks-per-node<span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--gpus-per-task<span class="o">=</span><span class="m">1</span><span class="w"> </span>--gpu-bind<span class="o">=</span>single:1<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--mpi<span class="o">=</span>pmix<span class="w"> </span>-C<span class="w"> </span>gpu<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>legate<span class="w"> </span>--gpus<span class="w"> </span><span class="m">1</span><span class="w"> </span>--profile<span class="w"> </span>myprog.py
</pre></div>
</div>
<p>Similarly, a program can be run via the <code class="docutils literal notranslate"><span class="pre">LEGATE_CONFIG</span></code> environment
variable:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">LEGATE_CONFIG</span><span class="o">=</span><span class="s2">&quot;--cpus 8 --sysmem 4000 --profile&quot;</span><span class="w"> </span>python<span class="w"> </span>./myprog.py
</pre></div>
</div>
<p><strong>3.) After a run completes, in the directory you ran the command youll see:</strong></p>
<ul class="simple">
<li><p>One or more raw trace files: <code class="docutils literal notranslate"><span class="pre">legate_*.prof</span></code> (one per rank)</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">legate_*.prof</span></code> files are what you need to view locally on your machine.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># CPU / Single GPU - Will only produce 1 file (1 rank)
legate_0.prof
legate_prof/

# Multi-GPU - Will produce 1 file per rank (4 ranks)
legate_0.prof
legate_1.prof
legate_2.prof
legate_3.prof
legate_prof/

# Multi-Node (multi-rank; e.g, 2 nodes x 4 GPUs = 8 ranks)
legate_0.prof ... legate_7.prof
legate_prof/
</pre></div>
</div>
<p><strong>Note:</strong> Trace files are numbered by rank index (e.g., <code class="docutils literal notranslate"><span class="pre">legate_0.prof</span></code>, <code class="docutils literal notranslate"><span class="pre">legate_1.prof</span></code>), not by run. If you run again in the same directory, files with the same rank numbers will be overwritten; for example, a 1-rank run will replace <code class="docutils literal notranslate"><span class="pre">legate_0.prof</span></code>. The <code class="docutils literal notranslate"><span class="pre">legate_prof/</span></code> HTML report directory is also overwritten.</p>
<p><strong>4.) Local Setup:</strong> WSL, Miniforge (Conda), and Legate + Legate profiler viewer</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#These commands will work directly on a Linux environment.</span>
<span class="c1">#For Windows OS  open Ubuntu/WSL2 (Windows Subsystem for Linux), install Miniforge (Conda), and activate it.</span>

<span class="c1"># Download installer</span>
wget<span class="w"> </span>https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh

<span class="c1"># Install into home</span>
bash<span class="w"> </span>Miniforge3-Linux-x86_64.sh<span class="w"> </span>-b<span class="w"> </span>-p<span class="w"> </span><span class="s2">&quot;</span><span class="nv">$HOME</span><span class="s2">/miniforge3&quot;</span>

<span class="c1"># Load Conda into current shell</span>
<span class="nb">source</span><span class="w"> </span><span class="s2">&quot;</span><span class="nv">$HOME</span><span class="s2">/miniforge3/etc/profile.d/conda.sh&quot;</span>

<span class="c1"># Configure future shells</span>
conda<span class="w"> </span>init<span class="w"> </span>bash

<span class="c1"># Restart shell to apply changes</span>
<span class="nb">exec</span><span class="w"> </span><span class="nv">$SHELL</span><span class="w"> </span>-l

<span class="c1"># Create and activate an environment with Legate + cuPyNumeric + the profile viewer</span>
conda<span class="w"> </span>create<span class="w"> </span>-n<span class="w"> </span>legate<span class="w"> </span>-y<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>-c<span class="w"> </span>legate<span class="w"> </span>legate<span class="w"> </span>cupynumeric<span class="w"> </span>legate-profiler
conda<span class="w"> </span>activate<span class="w"> </span>legate
</pre></div>
</div>
<p><strong>5.) Copy files to your local device:</strong> Create a single top-level folder &amp; keep
runs separated to avoid name/file clashes:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copy legate_*.prof file(s) for CPU, single-GPU, Multi-GPU, or Multi-Node</span>
scp<span class="w"> </span>-r<span class="w"> </span>&lt;USER&gt;@&lt;REMOTE_HOST&gt;:&lt;REMOTE_RUN_DIR&gt;/legate_*.prof<span class="w"> </span><span class="se">\</span>
<span class="w">      </span><span class="s2">&quot;&lt;LOCAL_DIR&gt;/&lt;FOLDER_NAME&gt;/name_of_run&quot;</span>
</pre></div>
</div>
<p><strong>6.) In local machine, use the following command to open files with the profile
viewer:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># CPU/GPU: single file (rank 0/N0)</span>
legate_prof<span class="w"> </span>view<span class="w"> </span>/path/to/legate_0.prof

<span class="c1"># Multi-GPU/Multi-Node: multiple ranks (pass them all: e.g: N0, N1, N2, etc)</span>
legate_prof<span class="w"> </span>view<span class="w"> </span>/path/to/legate_*.prof
</pre></div>
</div>
<p><strong>For more detail, see the official references:</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.nvidia.com/legate/latest/manual/usage/index.html">Usage  NVIDIA legate</a></p></li>
</ul>
</section>
<section id="profiling-cupynumeric-applications-with-legate-profilers-example-1">
<h2>Profiling cuPyNumeric Applications with Legate Profilers  Example 1<a class="headerlink" href="#profiling-cupynumeric-applications-with-legate-profilers-example-1" title="Link to this heading">#</a></h2>
<section id="inefficient-code">
<h3>Inefficient code<a class="headerlink" href="#inefficient-code" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">cupynumeric</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">10_000_000</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># advanced indexing, extra comms/overhead</span>
<span class="n">cond_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">((</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mf">0.25</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">))</span>

<span class="c1"># extra temporaries</span>
<span class="n">z</span>     <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="n">z_alt</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span> <span class="o">+</span> <span class="mf">1.0</span>

<span class="c1"># scatter writeback through indices (slower than boolean mask)</span>
<span class="n">z</span><span class="p">[</span><span class="n">cond_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">z_alt</span><span class="p">[</span><span class="n">cond_idx</span><span class="p">]</span>

<span class="c1"># tiny chunked updates, lots of tiny tasks</span>
<span class="n">CHUNK</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">CHUNK</span><span class="p">):</span>
    <span class="n">sub</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="n">s</span><span class="p">:</span><span class="n">s</span><span class="o">+</span><span class="n">CHUNK</span><span class="p">]</span>
    <span class="n">gt1</span> <span class="o">=</span> <span class="n">sub</span> <span class="o">&gt;</span> <span class="mf">1.0</span>
    <span class="n">sub</span><span class="p">[</span><span class="n">gt1</span><span class="p">]</span>  <span class="o">=</span> <span class="n">sub</span><span class="p">[</span><span class="n">gt1</span><span class="p">]</span>  <span class="o">+</span> <span class="mf">2.0</span>
    <span class="n">sub</span><span class="p">[</span><span class="o">~</span><span class="n">gt1</span><span class="p">]</span> <span class="o">=</span> <span class="n">sub</span><span class="p">[</span><span class="o">~</span><span class="n">gt1</span><span class="p">]</span> <span class="o">-</span> <span class="mf">2.0</span>
</pre></div>
</div>
</section>
<section id="how-this-code-works">
<h3>How this code works<a class="headerlink" href="#how-this-code-works" title="Link to this heading">#</a></h3>
<p>This script builds two large random arrays, forms <code class="docutils literal notranslate"><span class="pre">z</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">+</span> <span class="pre">y</span></code>, then
selectively overwrites elements of <code class="docutils literal notranslate"><span class="pre">z</span></code> with <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">*</span> <span class="pre">y</span> <span class="pre">+</span> <span class="pre">1.0</span></code> where
<code class="docutils literal notranslate"><span class="pre">(x</span> <span class="pre">&lt;</span> <span class="pre">0.25)</span> <span class="pre">&amp;</span> <span class="pre">(y</span> <span class="pre">&gt;</span> <span class="pre">0.5)</span></code>, and finally inserts values above and below 1.0
by 2.0. The performance suffers for three core reasons. First, it uses
<code class="docutils literal notranslate"><span class="pre">nonzero(...)</span></code> to create large integer index arrays and then scatters values
back into <code class="docutils literal notranslate"><span class="pre">z</span></code>, which adds metadata handling and communication overhead
compared with simple boolean masks. Second, it creates extra temporaries
(<code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">+</span> <span class="pre">y</span></code> and <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">*</span> <span class="pre">y</span> <span class="pre">+</span> <span class="pre">1.0</span></code>) instead of writing results into a preallocated
output, increasing memory traffic and allocations. Third, it processes the
array in 4,096-element slices, creating thousands of tiny tasks; the runtime
spends a disproportionate amount of time scheduling and synchronizing rather
than executing useful work. These choices increase memory pressure,
task-launch overhead, and communication costs, making the computation scale
poorly compared to a more direct, vectorized approach.</p>
<section id="array-creation">
<h4>Array creation<a class="headerlink" href="#array-creation" title="Link to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p>The snippet generates two large input arrays but uses <code class="docutils literal notranslate"><span class="pre">.astype(...)</span></code>, which
forces an extra copy instead of producing the target data type directly.
<code class="docutils literal notranslate"><span class="pre">np.random.random(N)</span></code> returns <code class="docutils literal notranslate"><span class="pre">float64</span></code>, and produces an array of length
<code class="docutils literal notranslate"><span class="pre">N</span></code> filled with random floats sampled from <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1)</span></code>. The
<code class="docutils literal notranslate"><span class="pre">.astype(np.float32)</span></code> converts it to single precision (<code class="docutils literal notranslate"><span class="pre">float32</span></code>), which
halves the memory footprint.</p>
</section>
<section id="index-selection-via-nonzero">
<h4>Index selection via <code class="docutils literal notranslate"><span class="pre">nonzero</span></code><a class="headerlink" href="#index-selection-via-nonzero" title="Link to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cond_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">((</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mf">0.25</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">))</span>
</pre></div>
</div>
<p>Here the code builds index arrays with <code class="docutils literal notranslate"><span class="pre">nonzero</span></code>. <code class="docutils literal notranslate"><span class="pre">nonzero</span></code> builds large
index arrays and forces a scatter write, increasing memory use and
kernel/communication overhead compared to a single, contiguous masked update.</p>
</section>
<section id="temporaries">
<h4>Temporaries<a class="headerlink" href="#temporaries" title="Link to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">z</span>     <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="n">z_alt</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span> <span class="o">+</span> <span class="mf">1.0</span>
</pre></div>
</div>
<p>This section creates two large temporaries, increasing memory traffic and
allocations.</p>
</section>
<section id="scatter-assignment">
<h4>Scatter assignment<a class="headerlink" href="#scatter-assignment" title="Link to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">z</span><span class="p">[</span><span class="n">cond_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">z_alt</span><span class="p">[</span><span class="n">cond_idx</span><span class="p">]</span>
</pre></div>
</div>
<p>Now the code scatters values back into <code class="docutils literal notranslate"><span class="pre">z</span></code> using advanced indexing, adding
overhead compared to mask-based updates.</p>
</section>
<section id="tiny-chunk-loop">
<h4>Tiny-chunk loop<a class="headerlink" href="#tiny-chunk-loop" title="Link to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">CHUNK</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">CHUNK</span><span class="p">):</span>
    <span class="n">sub</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="n">s</span><span class="p">:</span><span class="n">s</span><span class="o">+</span><span class="n">CHUNK</span><span class="p">]</span>
    <span class="n">gt1</span> <span class="o">=</span> <span class="n">sub</span> <span class="o">&gt;</span> <span class="mf">1.0</span>
    <span class="n">sub</span><span class="p">[</span><span class="n">gt1</span><span class="p">]</span>  <span class="o">=</span> <span class="n">sub</span><span class="p">[</span><span class="n">gt1</span><span class="p">]</span>  <span class="o">+</span> <span class="mf">2.0</span>
    <span class="n">sub</span><span class="p">[</span><span class="o">~</span><span class="n">gt1</span><span class="p">]</span> <span class="o">=</span> <span class="n">sub</span><span class="p">[</span><span class="o">~</span><span class="n">gt1</span><span class="p">]</span> <span class="o">-</span> <span class="mf">2.0</span>
</pre></div>
</div>
<p>Finally the code breaks the array into thousands of small slices, which results
in many tiny tasks; runtime overhead dominates useful computation.</p>
</section>
</section>
<section id="profiler-output-and-interpretation-inefficient-cpu-results">
<h3>Profiler Output and Interpretation - Inefficient CPU Results<a class="headerlink" href="#profiler-output-and-interpretation-inefficient-cpu-results" title="Link to this heading">#</a></h3>
<a class="reference internal image-reference" href="../_images/Inefficient_profile1.png"><img alt="Inefficient profiler overview" src="../_images/Inefficient_profile1.png" style="width: 90%;" />
</a>
<p><strong>Interpretation:</strong> The profiler is presented as a timeline. The <strong>x-axis</strong> is time, the <strong>y-axis</strong> is organized
by resource/utilization lanes. Each horizontal lane represents a particular resource stream
(CPU workers, GPU Device/Host, runtime/Utility threads, memory pools like Framebuffer/Zerocopy,
and copy/Channel). Colored boxes show work on that resource; the box width is how long it ran,
gaps indicate idle/waiting, and dense barcode slivers usually mean many tiny tasks (high overhead),
while long solid blocks indicate fewer, larger tasks (better utilization).</p>
<section id="cpu">
<h4>1) CPU<a class="headerlink" href="#cpu" title="Link to this heading">#</a></h4>
<section id="what-this-shows">
<h5>What this shows<a class="headerlink" href="#what-this-shows" title="Link to this heading">#</a></h5>
<p>Users compute tasks, computations, and data movement on main CPU worker
cores. Long, solid bars means a few large tasks/operations (good). Dense
bar-code slivers means many tiny tasks (bad). This is where you read task
time and spot idle gaps between tasks.</p>
<a class="reference internal image-reference" href="../_images/Inefficient_CPU2.png"><img alt="Inefficient CPU profiler timeline with many tiny tasks" src="../_images/Inefficient_CPU2.png" style="width: 90%;" />
</a>
<p><strong>Zoomed in:</strong></p>
<a class="reference internal image-reference" href="../_images/Inefficient_CPU3.png"><img alt="Inefficient CPU timeline (zoom 2)" src="../_images/Inefficient_CPU3.png" style="width: 90%;" />
</a>
<p><strong>CPU Observation:</strong></p>
<p>Start-up shows a few large initialization tasks. After that, the 4,096-element
slice loop fragments work into many small tasks, producing a barcode-like
pattern. This displays overly fine-grained work that increases
scheduling/launch overhead, creates idle gaps, and lowers CPU efficiency. Each
small sliver represents merged tasks that execute separate small
computations.</p>
</section>
<section id="cpu-avg">
<h5>CPU Avg<a class="headerlink" href="#cpu-avg" title="Link to this heading">#</a></h5>
<a class="reference internal image-reference" href="../_images/Inefficient_CPU_avg4.png"><img alt="Inefficient CPU timeline (zoom 2)" src="../_images/Inefficient_CPU_avg4.png" style="width: 90%;" />
</a>
<p>We observe a sharp startup spike in the CPU average line (~74% utilization),
followed by a long, low plateau. The spike corresponds to the large
element-wise operations (<code class="docutils literal notranslate"><span class="pre">z</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">+</span> <span class="pre">y</span></code>, <code class="docutils literal notranslate"><span class="pre">z_alt</span> <span class="pre">=</span> <span class="pre">x*y</span> <span class="pre">+</span> <span class="pre">1.0</span></code>). The subsequent
flat, low amplitude reflects the <code class="docutils literal notranslate"><span class="pre">CHUNK</span> <span class="pre">=</span> <span class="pre">4096</span></code> loop breaking work into
thousands of short slices, so cores never fully saturate. In the worker lanes
(c2-c9), this appears as a few early long, dark bars for the big operations,
then dense bar-code slivers across many cores for the rest of the run. Each
sliver is a tiny task from the slice loop. This fragmentation is bad: it
reduces sustained CPU utilization, increases context switching, and hurts cache
locality, so time shifts from steady computation to orchestrating tiny tasks.</p>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 100.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>What would good look like?</strong> A handful of long bars for the main operations, then just two long masked           updates (plus/minus 2.0 step), as opposed to thousands of slivers.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="utility">
<h4>2) Utility<a class="headerlink" href="#utility" title="Link to this heading">#</a></h4>
<a class="reference internal image-reference" href="../_images/Inefficient_utility5.png"><img alt="Inefficient utility lane (raw)" src="../_images/Inefficient_utility5.png" style="width: 90%;" />
</a>
<section id="id1">
<h5>What this shows<a class="headerlink" href="#id1" title="Link to this heading">#</a></h5>
<p>Legate runtime meta work: dependence analysis, mapping, task launch, and
coordination. These are tasks needed for the library to function but are not
the users computation. You want short bursts around big tasks/operations.
A sustained plateau means the scheduler is the bottleneck (threads are waiting
on runtime work).</p>
<p><strong>Utility Observation:</strong></p>
<p>Sustained high activity almost the entire run, with only a late drop, runtime
overhead dominates while on the other hand the computation is fragmented.</p>
</section>
<section id="utility-avg">
<h5>Utility Avg<a class="headerlink" href="#utility-avg" title="Link to this heading">#</a></h5>
<a class="reference internal image-reference" href="../_images/Inefficient_utility_avg6.png"><img alt="Inefficient utility lane (raw)" src="../_images/Inefficient_utility_avg6.png" style="width: 90%;" />
</a>
<p>We observe a quick ramp-up into a long, flat plateau on the utility-average
line, followed by a drop near the end. The plateau indicates the runtime is
continuously mapping, performing dependency analysis, and launching thousands
of micro-tasks created by the <code class="docutils literal notranslate"><span class="pre">CHUNK</span> <span class="pre">=</span> <span class="pre">4096</span></code> slice loop. Near the tail, the
utility load decreases because launches are over and only cleanup/final copies
remain. In the utility lanes (u0-u1), this appears as dense confetti of tiny
meta-tasks, which is the signature of over-granularity keeping the scheduler
busy almost all the time. The slice loop (<code class="docutils literal notranslate"><span class="pre">for</span> <span class="pre">s</span> <span class="pre">in</span> <span class="pre">range(0,</span> <span class="pre">N,</span> <span class="pre">4096)</span></code>)
drives persistent mapping/launch work; the index selection + scatter pattern
(<code class="docutils literal notranslate"><span class="pre">nonzero</span></code> + <code class="docutils literal notranslate"><span class="pre">z[idx]</span> <span class="pre">=</span> <span class="pre"></span></code>) adds per-slice dependence checks and
data-placement decisions; and extra temporaries (<code class="docutils literal notranslate"><span class="pre">z</span></code>, <code class="docutils literal notranslate"><span class="pre">z_alt</span></code>) create more
instances for the runtime to allocate and track. Bottom line: bad, time is
more so spent orchestrating rather than computing, often coinciding with idle
gaps on the CPU lanes.</p>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 100.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>What would good look like?</strong> Short, discrete bursts around a few large tasks/operations (in-place add,           one masked overwrite, two whole-array threshold updates), with the utility lanes mostly quiet between them.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="i-o-input-output">
<h4>3) I/O (input/output)<a class="headerlink" href="#i-o-input-output" title="Link to this heading">#</a></h4>
<a class="reference internal image-reference" href="../_images/Inefficient_IO7.png"><img alt="Inefficient I/O lane (raw)" src="../_images/Inefficient_IO7.png" style="width: 90%;" />
</a>
<section id="id2">
<h5>What this shows<a class="headerlink" href="#id2" title="Link to this heading">#</a></h5>
<p>This lane is Legate <code class="docutils literal notranslate"><span class="pre">TopLevelTask</span></code> / driver time; file reads/writes are a
subset. Use it alongside Channel (which records data between host and device)
to reason about data movement. Spikes usually reflect large reads/writes or
heavy top-level coordination; a thin, steady baseline suggests many small
I/O/driver events. GPU or CPU gaps often correlate with I/O or Channel
activity, but can also come from Utility (mapping) or dependencies.</p>
<p><strong>I/O observation:</strong></p>
<p>We see early heavy activity due to big copies, then a long low baseline of
small transfers, followed by a tall plateau near the end. The large data
movement pattern itself comes through Channel (scatter writes + tiny chunks),
while the I/O lane shows the top-level Python/driver work around it. The dark
magenta color represents I/O tasks actively executing. The lighter pink you
see earlier are the same I/O tasks while waiting/ready but not running yet.
The profiler will use shade to indicate state:</p>
<ul class="simple">
<li><p>Darkest shade = actively executing</p></li>
<li><p>Intermediate shade = ready state</p></li>
<li><p>Lightest shade = task is blocked</p></li>
<li><p>Gray = groups of tiny tasks</p></li>
</ul>
</section>
<section id="i-o-avg">
<h5>I/O Avg<a class="headerlink" href="#i-o-avg" title="Link to this heading">#</a></h5>
<a class="reference internal image-reference" href="../_images/Inefficient_IO_avg8.png"><img alt="Inefficient I/O lane (raw)" src="../_images/Inefficient_IO_avg8.png" style="width: 90%;" />
</a>
<p>We observe an early spike that settles into a short plateau as the program
initializes and writes full arrays for the temporaries (<code class="docutils literal notranslate"><span class="pre">z</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">+</span> <span class="pre">y</span></code>,
<code class="docutils literal notranslate"><span class="pre">z_alt</span> <span class="pre">=</span> <span class="pre">x*y</span> <span class="pre">+</span> <span class="pre">1.0</span></code>). This transitions into a long, low baseline reflecting
ongoing top-level coordination associated with many small, non-contiguous
transfers triggered by the <code class="docutils literal notranslate"><span class="pre">nonzero</span></code> scatter and the <code class="docutils literal notranslate"><span class="pre">CHUNK</span> <span class="pre">=</span> <span class="pre">4096</span></code> slice
loop (youll see the transfer shape itself in Channel as a thin, persistent
baseline). Near the end, the line rises again, a late plateau, as outstanding
copies drain and instances are finalized during cleanup, then it drops to
zero. Bottom line: Bad, more time is going to data movement/coordination
instead of compute, and it correlates with high Utility and fragmented CPU
(idle/long-poll symptoms).</p>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 100.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>What would good look like?</strong> Brief I/O bursts only: write once to a preallocated output, one masked               overwrite, then quiet channels, few wide transfers, no long baseline.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="system">
<h4>4) System<a class="headerlink" href="#system" title="Link to this heading">#</a></h4>
<section id="id3">
<h5>What this shows<a class="headerlink" href="#id3" title="Link to this heading">#</a></h5>
<p>Low-level system memory activity: allocations, thread/process setup, OS
interaction, and other background work. It should be quiet and flat during
steady computation.</p>
<a class="reference internal image-reference" href="../_images/Inefficient_system_avg9.png"><img alt="Inefficient system lane average" src="../_images/Inefficient_system_avg9.png" style="width: 90%;" />
</a>
<p><strong>System Observation:</strong></p>
<p>We observe a small early bump from normal startup work (process/thread creation
and initial allocation), followed by a flat, low sitting plateau indicating
minimal ongoing system overhead, and a slight dip at the end as the program
shuts down and cleans up. Bottom line: good/neutral, system stays low and
stable; the real bottlenecks are elsewhere (CPU fragmentation, Utility
overhead, and I/O/Channel traffic).</p>
</section>
</section>
<section id="channel-chan">
<h4>5) Channel (chan)<a class="headerlink" href="#channel-chan" title="Link to this heading">#</a></h4>
<section id="id4">
<h5>What this shows<a class="headerlink" href="#id4" title="Link to this heading">#</a></h5>
<p>Communication pathways grouped by source to destination memory. These are the
Direct Memory Access (DMA) copies that move data between host DRAM, GPU
Framebuffer memory, zero-copy memory, and sometimes system/network buffers.
Tall wide bursts mean large continuous transfers (efficient). Thin, persistent
baselines means many small transfers, often from over-granular work
(scatter/gather, slice loops).</p>
<a class="reference internal image-reference" href="../_images/Inefficient_channel10.png"><img alt="Inefficient Channel lane (raw 1)" src="../_images/Inefficient_channel10.png" style="width: 90%;" />
</a>
<a class="reference internal image-reference" href="../_images/Inefficient_channel11.png"><img alt="Inefficient Channel lane (raw 2)" src="../_images/Inefficient_channel11.png" style="width: 90%;" />
</a>
<p><strong>Channel Observation:</strong></p>
<p>The gray rectangles are merged visuals: when zoomed out, the profiler compacts
hundreds/thousands of micro-copies into gray bands; zooming in reveals the
individual narrow copy boxes, confirming over-granularity. Net effect: poor
effective throughput, each micro-copy pays setup/latency and increases
mapping/synchronization load (seen as a busy Utility lane), and the fragmented
transfers create idle gaps on CPU lanes while tasks wait for data.</p>
</section>
<section id="channel-avg">
<h5>Channel Avg<a class="headerlink" href="#channel-avg" title="Link to this heading">#</a></h5>
<a class="reference internal image-reference" href="../_images/Inefficient_channel_avg12.png"><img alt="Inefficient Channel average utilization" src="../_images/Inefficient_channel_avg12.png" style="width: 90%;" />
</a>
<p>One early blip (initial large copy into device memory), then a long, faint
baseline, which is the flood of small scatter/gather copies from
<code class="docutils literal notranslate"><span class="pre">nonzero(...)</span></code> indexing and the <code class="docutils literal notranslate"><span class="pre">CHUNK</span> <span class="pre">=</span> <span class="pre">4096</span></code> loop. Each tiny slice
forces its own DMA operation.</p>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 100.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>What would good look like?</strong> A handful of short, tall bursts around the major steps: write once into             <code class="docutils literal notranslate"><span class="pre">z</span></code>, do a single masked overwrite for the condition, then perform two whole-array threshold updates.             Between bursts the baseline stays quiet, utility lanes are mostly idle, and CPU lanes show long, solid bars        instead of bar-code slivers.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="dependent-partitioning-dp">
<h4>6) Dependent Partitioning (dp)<a class="headerlink" href="#dependent-partitioning-dp" title="Link to this heading">#</a></h4>
<section id="id5">
<h5>What this shows<a class="headerlink" href="#id5" title="Link to this heading">#</a></h5>
<a class="reference internal image-reference" href="../_images/Inefficient_DP_avg13.png"><img alt="Inefficient dependent partitioning average" src="../_images/Inefficient_DP_avg13.png" style="width: 90%;" />
</a>
<p>Time the runtime spends creating dependent region partitions (subregions
derived from other regions), this is needed for sliced, indirect, or masked
operations. Partitioning must finish before mapping/copies can proceed. Its a
niche, hyper-specific metric that often reads near zero in simple workloads,
but can matter in more complex applications (e.g., sparse matrix operations,
irregular graphs, adaptive meshes) where partition shapes change frequently.</p>
<p><strong>DP Observation:</strong></p>
<p>The dp avg line is flat at ~0% utilization for the whole run, indicating
partition work is negligible in total time. In dp0 you still see a long gray
merged band: thats the view compacting many ultra-short partition events
(from the 4,096-element slice loop and the <code class="docutils literal notranslate"><span class="pre">nonzero(...)</span></code> scatter) into a
single bar at this zoom level. Each event is tiny, so even though there are
lots of them, their duty cycle is so low that average utilization rounds to
zero.</p>
</section>
<section id="interpretation">
<h5>Interpretation<a class="headerlink" href="#interpretation" title="Link to this heading">#</a></h5>
<p>Partition creation is not the primary bottleneck here (Utility and Channel
are). However, those micro-partitions still add overhead and can lengthen
critical paths by forcing extra dependencies before copies/updates launch. The
better alternative would be to keep dp light by avoiding per-slice/indirect
updates and preferring whole-array masked writes and reused partitions so the
runtime doesnt need to generate countless micro-partitions.</p>
</section>
</section>
</section>
<section id="inefficient-gpu-results-4-ranks-1-gpu-each">
<h3>Inefficient GPU Results - (4 Ranks 1 GPU each)<a class="headerlink" href="#inefficient-gpu-results-4-ranks-1-gpu-each" title="Link to this heading">#</a></h3>
<p>All ranks:</p>
<a class="reference internal image-reference" href="../_images/gpu_Inefficient14.png"><img alt="Inefficient GPU overview (all ranks)" src="../_images/gpu_Inefficient14.png" style="width: 90%;" />
</a>
<p><strong>Interpretation:</strong> The profiler is presented as a timeline. The <strong>x-axis</strong> is time, the <strong>y-axis</strong> is organized
by resource/utilization lanes. Each horizontal lane represents a particular resource stream
(CPU workers, GPU Device/Host, runtime/Utility threads, memory pools like Framebuffer/Zerocopy,
and copy/Channel). Colored boxes show work on that resource; the box width is how long it ran,
gaps indicate idle/waiting, and dense barcode slivers usually mean many tiny tasks (high overhead),
while long solid blocks indicate fewer, larger tasks (better utilization).</p>
<section id="gpu-dev">
<h4>1) GPU Dev<a class="headerlink" href="#gpu-dev" title="Link to this heading">#</a></h4>
<section id="id6">
<h5>What this shows<a class="headerlink" href="#id6" title="Link to this heading">#</a></h5>
<p>Execution of kernels directly on the GPU Device. This lane measures how long
GPU execution units are busy running element-wise operations, reductions,
matrix kernels, etc. High steady utilization means kernels are big and
well-batched; low or jagged utilization means the GPU is either idle or
getting too many tiny launches.</p>
<a class="reference internal image-reference" href="../_images/gpuDev_Inefficient15.png"><img alt="Inefficient GPU device lane" src="../_images/gpuDev_Inefficient15.png" style="width: 90%;" />
</a>
<p><strong>GPU Dev Observation:</strong></p>
<p>In the GPU Dev lane we see wide gray bands at zoom compress many
micro-kernels; zooming in reveals dense strips, each a tiny kernel from the
4,096-element slices or the scatter path. Above that we see many repeated,
sawtooth-like spikes rather than long, solid bars. <code class="docutils literal notranslate"><span class="pre">z</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">+</span> <span class="pre">y</span></code> and
<code class="docutils literal notranslate"><span class="pre">z_alt</span> <span class="pre">=</span> <span class="pre">x*</span> <span class="pre">y</span> <span class="pre">+</span> <span class="pre">1.0</span></code> each launch element-wise kernels early (brief higher
utilization). <code class="docutils literal notranslate"><span class="pre">cond_idx</span> <span class="pre">=</span> <span class="pre">np.nonzero((x</span> <span class="pre">&lt;</span> <span class="pre">0.25)</span> <span class="pre">&amp;</span> <span class="pre">(y</span> <span class="pre">&gt;</span> <span class="pre">0.5))</span></code> computes a
boolean test and then materializes index arrays; subsequent
<code class="docutils literal notranslate"><span class="pre">z[cond_idx]</span> <span class="pre">=</span> <span class="pre">z_alt[cond_idx]</span></code> performs a scatter update that splits work,
producing multiple small kernels instead of one contiguous masked write. The
loop with <code class="docutils literal notranslate"><span class="pre">CHUNK</span> <span class="pre">=</span> <span class="pre">4096</span></code> (<code class="docutils literal notranslate"><span class="pre">sub</span> <span class="pre">=</span> <span class="pre">z[s:s+CHUNK]</span></code>; threshold; two per-slice
updates) generates thousands of tiny, per-chunk kernels. Each chunk does:
compare, select, then two updates, so the device keeps starting and stopping
kernels rather than running a few big ones.</p>
</section>
<section id="gpu-dev-avg">
<h5>GPU Dev Avg<a class="headerlink" href="#gpu-dev-avg" title="Link to this heading">#</a></h5>
<a class="reference internal image-reference" href="../_images/gpuDev_Inefficient_avg16.png"><img alt="Inefficient GPU device average utilization" src="../_images/gpuDev_Inefficient_avg16.png" style="width: 90%;" />
</a>
<p>At startup the line lifts due to big element-wise operations. It then gradually
sinks lower, oscillating high to low. That indicates persistent GPU activity,
but fine granularity: per-chunk/per-scatter kernels are short, so launch
overhead and synchronization eats into total time.</p>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 100.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>What would good look like?</strong> A few long, contiguous kernels that keep the device busy: one large vector          add, one single masked overwrite (no scatter), etc. The GPU Dev lane shows long solid bars with a high,            steady average line, minimal gaps between kernels, and compute overlapping cleanly with a few bulk copies          (seen in Channel).</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="gpu-host">
<h4>2) GPU Host<a class="headerlink" href="#gpu-host" title="Link to this heading">#</a></h4>
<section id="id7">
<h5>What this shows<a class="headerlink" href="#id7" title="Link to this heading">#</a></h5>
<p>CPU-side orchestration for GPU work: kernel launches, argument setup,
enqueueing tasks, and prepping memory transfers. You want brief bursts per
large kernel, not continuous chatter/oscillation.</p>
<a class="reference internal image-reference" href="../_images/gpuHost_Inefficient17.png"><img alt="Inefficient GPU host lane (raw)" src="../_images/gpuHost_Inefficient17.png" style="width: 90%;" />
</a>
<p><strong>GPU Host Observation:</strong></p>
<p>Frequent spikes/oscillations mirror GPU Dev, such that the code launches many
tiny kernels:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">nonzero(...)</span></code> + <code class="docutils literal notranslate"><span class="pre">z[cond_idx]</span> <span class="pre">=</span> <span class="pre">z_alt[cond_idx]</span></code> adds scatter setup and
extra small launches.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CHUNK</span> <span class="pre">=</span> <span class="pre">4096</span></code> loop creates per-slice compare + two updates, so the host
repeatedly launches micro-kernels.</p></li>
</ul>
</section>
<section id="gpu-host-avg">
<h5>GPU Host Avg<a class="headerlink" href="#gpu-host-avg" title="Link to this heading">#</a></h5>
<a class="reference internal image-reference" href="../_images/gpuHost_Inefficient_avg18.png"><img alt="Inefficient GPU host average utilization" src="../_images/gpuHost_Inefficient_avg18.png" style="width: 90%;" />
</a>
<p>High, jagged baseline after a startup spike means launch overhead is sustained.
Host time tracks GPU Dev closely, an obvious indication of over-granularity
(per-launch cost comparable to work done).</p>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 100.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>What would good look like?</strong> Sparse, short spikes only when launching those few large kernels. The GPU           Host lane is a little lower and quieter than GPU Dev. Brief bursts at kernel starts, then long idle periods        while the device executes. No dense barcode of micro-launches. Will look very similar to GPU Dev.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="zerocopy">
<h4>3) Zerocopy<a class="headerlink" href="#zerocopy" title="Link to this heading">#</a></h4>
<section id="id8">
<h5>What this shows<a class="headerlink" href="#id8" title="Link to this heading">#</a></h5>
<p>Transfers between CPU host memory and GPU memory using pinned host memory
directly accessible by the GPU. Useful when data is accessed only once or in
small pieces. Ideally, you see just a few bursts; heavy use usually means data
isnt staged efficiently in device memory.</p>
<a class="reference internal image-reference" href="../_images/ZC_Inefficient_avg19.png"><img alt="Inefficient Zerocopy average utilization" src="../_images/ZC_Inefficient_avg19.png" style="width: 90%;" />
</a>
<p><strong>Zerocopy Observation:</strong></p>
<p>The avg line is pinned at a ~0% utilization for the entire run. If this section
was expanded you would see many blocks gradually getting larger as you scroll
down due to the 4,096-element slice loop, but their duty cycle is so small that
utilization rounds to zero. Any zero-copy use here is incidental and negligible
compared with other streams. Zerocopy is not a bottleneck.</p>
</section>
</section>
<section id="framebuffer">
<h4>4) Framebuffer<a class="headerlink" href="#framebuffer" title="Link to this heading">#</a></h4>
<section id="id9">
<h5>What this shows<a class="headerlink" href="#id9" title="Link to this heading">#</a></h5>
<p>Time the profiler records GPU Framebuffer (device memory) allocation,
deallocation, or access overhead. This isnt the math itself, but the memory
management cost for storing temporaries and outputs in device memory. Ideally
this lane should stay low and quiet, with only brief bumps for allocation at
startup and cleanup at shutdown.</p>
<a class="reference internal image-reference" href="../_images/fb_Inefficient_avg20.png"><img alt="Inefficient framebuffer average utilization" src="../_images/fb_Inefficient_avg20.png" style="width: 90%;" />
</a>
<p>Framebuffer Observation:
The avg line rises gradually to ~23% utilization and holds steady through most
of the run, dipping only near the end. That reflects sustained
allocation/instance traffic, likely from:</p>
<ul class="simple">
<li><p>Extra temporaries (<code class="docutils literal notranslate"><span class="pre">z</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">+</span> <span class="pre">y</span></code>, <code class="docutils literal notranslate"><span class="pre">z_alt</span> <span class="pre">=</span> <span class="pre">x*y+1.0</span></code>) creating more device
instances than necessary.</p></li>
<li><p>Scatter updates (<code class="docutils literal notranslate"><span class="pre">z[cond_idx]</span> <span class="pre">=</span> <span class="pre"></span></code>) forcing additional partitioned storage.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">CHUNK</span> <span class="pre">=</span> <span class="pre">4096</span></code> loop repeatedly touching small subregions.</p></li>
</ul>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 100.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>What would good look like?</strong> A small bump at initialization (allocate main arrays), flat near zero during        steady compute, and a dip at the end (cleanup). No continuous Framebuffer overhead, just data living in            device memory for long stretches while kernels run.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
</section>
<section id="efficient-code">
<h3>Efficient Code<a class="headerlink" href="#efficient-code" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">cupynumeric</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">10_000_000</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># In-place sum without a temporary</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">z</span><span class="p">)</span>

<span class="c1"># Conditional overwrite with a boolean mask (faster than nonzero + scatter)</span>
<span class="n">cond</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mf">0.25</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">putmask</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">cond</span><span class="p">,</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># Wide masked updates, in-place</span>
<span class="n">gt1</span> <span class="o">=</span> <span class="n">z</span> <span class="o">&gt;</span> <span class="mf">1.0</span>
<span class="n">z</span><span class="p">[</span><span class="n">gt1</span><span class="p">]</span>  <span class="o">+=</span> <span class="mf">2.0</span>
<span class="n">z</span><span class="p">[</span><span class="o">~</span><span class="n">gt1</span><span class="p">]</span> <span class="o">-=</span> <span class="mf">2.0</span>
</pre></div>
</div>
</section>
<section id="id10">
<h3>How this code works<a class="headerlink" href="#id10" title="Link to this heading">#</a></h3>
<p>This program generates two large <code class="docutils literal notranslate"><span class="pre">float32</span></code> arrays directly from the Generator
API (no extra casts), computes <code class="docutils literal notranslate"><span class="pre">z</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">+</span> <span class="pre">y</span></code> directly into a preallocated
output, selectively overwrites elements of <code class="docutils literal notranslate"><span class="pre">z</span></code> with <code class="docutils literal notranslate"><span class="pre">x*y</span> <span class="pre">+</span> <span class="pre">1.0</span></code> where
<code class="docutils literal notranslate"><span class="pre">(x</span> <span class="pre">&lt;</span> <span class="pre">0.25)</span> <span class="pre">&amp;</span> <span class="pre">(y</span> <span class="pre">&gt;</span> <span class="pre">0.5)</span></code>, and then applies two wide, in-place updates that
add or subtract 2.0 based on whether values exceed 1.0. Its efficient because
it avoids unnecessary temporaries by writing into a preallocated array, uses a
boolean mask instead of creating index arrays, and performs the final
adjustments as wide vectorized operations rather than many small slices. These
choices reduce memory traffic, task-launch overhead, and communication costs,
leading to better utilization and scalability on both CPU and GPU.</p>
<section id="array-creation-data-type-copies">
<h4>Array creation (data type &amp; copies)<a class="headerlink" href="#array-creation-data-type-copies" title="Link to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># inefficient</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># efficient</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p>Using the Generator API, <code class="docutils literal notranslate"><span class="pre">rng</span> <span class="pre">=</span> <span class="pre">np.random.default_rng();</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">rng.random(N,</span>
<span class="pre">dtype=np.float32)</span></code>, creates arrays in the target dtype at the source, so
theres no <code class="docutils literal notranslate"><span class="pre">float64</span></code> to <code class="docutils literal notranslate"><span class="pre">float32</span></code> downcast and no extra allocation/copy.
That cuts memory traffic and peak footprint, improves cache/GPU memory
efficiency, and avoids the false impression that <code class="docutils literal notranslate"><span class="pre">astype(copy=False)</span></code> would
help, since casting to a new dtype always requires a copy. In short: fewer
bytes moved, fewer temporaries, faster start-up.</p>
</section>
<section id="base-computation">
<h4>Base computation<a class="headerlink" href="#base-computation" title="Link to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># inefficient</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>

<span class="c1"># efficient</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
<p>Both compute <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">+</span> <span class="pre">y</span></code>. The efficient code writes directly into a preallocated
output, avoiding a full temporary allocation and an extra pass over memory.
This reduces peak memory and improves cache/GPU memory efficiency.</p>
</section>
<section id="conditional-overwrite-indices-vs-mask">
<h4>Conditional overwrite (indices vs mask)<a class="headerlink" href="#conditional-overwrite-indices-vs-mask" title="Link to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># inefficient</span>
<span class="n">cond_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">((</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mf">0.25</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="n">z_alt</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span> <span class="o">+</span> <span class="mf">1.0</span>
<span class="n">z</span><span class="p">[</span><span class="n">cond_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">z_alt</span><span class="p">[</span><span class="n">cond_idx</span><span class="p">]</span>

<span class="c1"># efficient</span>
<span class="n">np</span><span class="o">.</span><span class="n">putmask</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mf">0.25</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>
</pre></div>
</div>
<p>The efficient version applies the condition directly inside <code class="docutils literal notranslate"><span class="pre">putmask</span></code>, so no
large index arrays are built and it is easier for the runtime to fuse/optimize.
This keeps the update lightweight and communication-friendly. The inefficient
version materializes index arrays, creates an additional full-size temporary
(<code class="docutils literal notranslate"><span class="pre">z_alt</span></code>), and performs a scatter assignment, each adding overhead.</p>
</section>
<section id="chunked-loop-vs-vectorized">
<h4>Chunked loop vs Vectorized<a class="headerlink" href="#chunked-loop-vs-vectorized" title="Link to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># inefficient</span>
<span class="n">CHUNK</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">CHUNK</span><span class="p">):</span>
    <span class="n">sub</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="n">s</span><span class="p">:</span><span class="n">s</span><span class="o">+</span><span class="n">CHUNK</span><span class="p">]</span>
    <span class="n">gt1</span> <span class="o">=</span> <span class="n">sub</span> <span class="o">&gt;</span> <span class="mf">1.0</span>
    <span class="n">sub</span><span class="p">[</span><span class="n">gt1</span><span class="p">]</span>  <span class="o">=</span> <span class="n">sub</span><span class="p">[</span><span class="n">gt1</span><span class="p">]</span>  <span class="o">+</span> <span class="mf">2.0</span>
    <span class="n">sub</span><span class="p">[</span><span class="o">~</span><span class="n">gt1</span><span class="p">]</span> <span class="o">=</span> <span class="n">sub</span><span class="p">[</span><span class="o">~</span><span class="n">gt1</span><span class="p">]</span> <span class="o">-</span> <span class="mf">2.0</span>

<span class="c1"># efficient</span>
<span class="n">gt1</span> <span class="o">=</span> <span class="n">z</span> <span class="o">&gt;</span> <span class="mf">1.0</span>
<span class="n">z</span><span class="p">[</span><span class="n">gt1</span><span class="p">]</span>  <span class="o">+=</span> <span class="mf">2.0</span>
<span class="n">z</span><span class="p">[</span><span class="o">~</span><span class="n">gt1</span><span class="p">]</span> <span class="o">-=</span> <span class="mf">2.0</span>
</pre></div>
</div>
<p>The efficient approach performs two wide, in-place vectorized updates over the
whole array. This eliminates thousands of tiny tasks, dramatically reducing
launch and scheduling overhead and improving GPU/CPU utilization. The more
regular access pattern also plays nicely with caches and the memory controller,
boosting overall utilization.</p>
</section>
</section>
<section id="profiler-output-and-interpretation-efficient-cpu-results">
<h3>Profiler Output and Interpretation - Efficient CPU Results<a class="headerlink" href="#profiler-output-and-interpretation-efficient-cpu-results" title="Link to this heading">#</a></h3>
<a class="reference internal image-reference" href="../_images/efficient_profiler21.png"><img alt="Efficient profiler overview" src="../_images/efficient_profiler21.png" style="width: 90%;" />
</a>
<p><strong>Interpretation:</strong> The profiler is presented as a timeline. The <strong>x-axis</strong> is time, the <strong>y-axis</strong> is organized
by resource/utilization lanes. Each horizontal lane represents a particular resource stream
(CPU workers, GPU Device/Host, runtime/Utility threads, memory pools like Framebuffer/Zerocopy,
and copy/Channel). Colored boxes show work on that resource; the box width is how long it ran,
gaps indicate idle/waiting, and dense barcode slivers usually mean many tiny tasks (high overhead),
while long solid blocks indicate fewer, larger tasks (better utilization).</p>
<section id="id11">
<h4>CPU<a class="headerlink" href="#id11" title="Link to this heading">#</a></h4>
<a class="reference internal image-reference" href="../_images/cpu_efficient22.png"><img alt="Efficient CPU timeline" src="../_images/cpu_efficient22.png" style="width: 90%;" />
</a>
<p><strong>Why this is good:</strong></p>
<p>Few longer bars, minimal barcode. Work is consolidated into large tasks;
cores stay busy with little orchestration. CPU avg: Large, contiguous vector
ops (add, mask, updates) keep per-task overhead tiny vs compute, so the
runtime batches the work rather than slicing it into thousands of tiny tasks.</p>
<p>Efficient Code:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">z</span> <span class="pre">=</span> <span class="pre">np.empty_like(x);</span> <span class="pre">np.add(x,</span> <span class="pre">y,</span> <span class="pre">out=z)</span></code>: leads to no temporary, it is
one large pass instead of build+copy.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">np.putmask(z,</span> <span class="pre">(x</span> <span class="pre">&lt;</span> <span class="pre">0.25)</span> <span class="pre">&amp;</span> <span class="pre">(y</span> <span class="pre">&gt;</span> <span class="pre">0.5),</span> <span class="pre">x*y</span> <span class="pre">+</span> <span class="pre">1.0)</span></code>: mask, not scatter;
avoids index arrays and irregular writes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">z[gt1]</span> <span class="pre">+=</span> <span class="pre">2.0;</span> <span class="pre">z[~gt1]</span> <span class="pre">-=</span> <span class="pre">2.0</span></code>: leads to two whole-array updates, no
<code class="docutils literal notranslate"><span class="pre">CHUNK</span> <span class="pre">=</span> <span class="pre">4096</span></code> loop, which means no thousands of tiny tasks.</p></li>
</ul>
</section>
<section id="id12">
<h4>Utility<a class="headerlink" href="#id12" title="Link to this heading">#</a></h4>
<a class="reference internal image-reference" href="../_images/utility_avg_efficient23.png"><img alt="Efficient utility average utilization" src="../_images/utility_avg_efficient23.png" style="width: 90%;" />
</a>
<a class="reference internal image-reference" href="../_images/utility_efficient24.png"><img alt="Efficient utility lane (raw 1)" src="../_images/utility_efficient24.png" style="width: 90%;" />
</a>
<a class="reference internal image-reference" href="../_images/utility_efficient25.png"><img alt="Efficient utility lane (raw 2)" src="../_images/utility_efficient25.png" style="width: 90%;" />
</a>
<p><strong>Why this is good:</strong></p>
<p>Quiet baseline with brief bursts at the end. Mapping/scheduling is compact;
most time is in real compute. The late burst corresponds to final mapping/sync
before completion. Little confetti in the utility lanes means few meta-tasks;
dependencies are simple and batched. Low avg line except at startup/teardown
mean orchestration cost is small vs. compute.</p>
<p>Efficient Code:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">np.add(x,</span> <span class="pre">y,</span> <span class="pre">out=z)</span></code>: one big operation; fewer instances to map/track.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">np.putmask(z,</span> <span class="pre">cond,</span> <span class="pre">x*y</span> <span class="pre">+</span> <span class="pre">1.0)</span></code>: mask, not scatter; avoids index arrays
and per-slice dependency checks.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">z[gt1]</span> <span class="pre">+=</span> <span class="pre">2.0;</span> <span class="pre">z[~gt1]</span> <span class="pre">-=</span> <span class="pre">2.0</span></code>: two whole-array updates, no
<code class="docutils literal notranslate"><span class="pre">CHUNK</span> <span class="pre">=</span> <span class="pre">4096</span></code> loop which means no thousands of tiny tasks.</p></li>
</ul>
</section>
<section id="i-o">
<h4>I/O<a class="headerlink" href="#i-o" title="Link to this heading">#</a></h4>
<a class="reference internal image-reference" href="../_images/io_efficient26.png"><img alt="Efficient I/O lane" src="../_images/io_efficient26.png" style="width: 90%;" />
</a>
<p><strong>Why this is good:</strong></p>
<p>The lane is dominated by a long, tall plateau that is a single TopLevelTask
block with only a few short blips for init/teardown, there is no mid-run I/O
plateaus. The avg line stays flat/low between blips with no steady chatter,
this means host to device copies are not here (theyd appear in Channel, which
stays quiet). Top-level orchestration is minimal, the time goes to compute,
not file I/O or driver overhead.</p>
<p>Efficient Code:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">np.add(x,</span> <span class="pre">y,</span> <span class="pre">out=z)</span></code>: writes directly to a preallocated output; avoids
extra writes/allocs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">np.putmask(z,</span> <span class="pre">cond,</span> <span class="pre">x*y</span> <span class="pre">+</span> <span class="pre">1.0)</span></code>: mask, not scatter; no index arrays,
fewer driver events.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">z[gt1]</span> <span class="pre">+=</span> <span class="pre">2.0;</span> <span class="pre">z[~gt1]</span> <span class="pre">-=</span> <span class="pre">2.0</span></code>: two whole-array updates, no
<code class="docutils literal notranslate"><span class="pre">CHUNK</span> <span class="pre">=</span> <span class="pre">4096</span></code> loop, so the runtime doesnt generate many tiny top-level
actions (Channel also stays free of thin, persistent copy baselines).</p></li>
</ul>
</section>
<section id="id13">
<h4>System<a class="headerlink" href="#id13" title="Link to this heading">#</a></h4>
<a class="reference internal image-reference" href="../_images/system_efficient27.png"><img alt="Efficient system lane" src="../_images/system_efficient27.png" style="width: 90%;" />
</a>
<p><strong>Why this is good:</strong></p>
<p>Near-zero for most of the run, with only a gradual rise to ~8% late in the
timeline (allocator growth/instance finalization/teardown). No mid-run
plateaus, the OS/allocator work isnt the bottleneck; compute and bulk copies
dominate.</p>
<p>Efficient Code:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">np.add(x,</span> <span class="pre">y,</span> <span class="pre">out=z)</span></code>: avoids an extra temporary/allocation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">np.putmask(z,</span> <span class="pre">cond,</span> <span class="pre">x*y</span> <span class="pre">+</span> <span class="pre">1.0)</span></code>: mask update, no large index arrays to
allocate/manage.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">z[gt1]</span> <span class="pre">+=</span> <span class="pre">2.0;</span> <span class="pre">z[~gt1]</span> <span class="pre">-=</span> <span class="pre">2.0</span></code>: two whole-array updates, no
<code class="docutils literal notranslate"><span class="pre">CHUNK</span> <span class="pre">=</span> <span class="pre">4096</span></code> loop, so far fewer small allocation/synchronization points
at the system.</p></li>
</ul>
</section>
<section id="id14">
<h4>Channel (chan)<a class="headerlink" href="#id14" title="Link to this heading">#</a></h4>
<a class="reference internal image-reference" href="../_images/channel_efficient28.png"><img alt="Efficient Channel lane" src="../_images/channel_efficient28.png" style="width: 90%;" />
</a>
<p><strong>Why this is good:</strong></p>
<p>Quiet baseline for most of the run; no thin, persistent copy noise. A couple
of tall plateaus only when needed for bulk transfers/flush at the end.
Indicates high effective throughput: few large DMA copies, minimal per-copy
overhead, and little sync pressure on Utility/CPU.</p>
<p>Efficient Code:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">np.add(x,</span> <span class="pre">y,</span> <span class="pre">out=z)</span></code>: writes once into a preallocated output; avoids
extra traffic.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">np.putmask(z,</span> <span class="pre">cond,</span> <span class="pre">x*y</span> <span class="pre">+</span> <span class="pre">1.0)</span></code>: boolean mask, not scatter; no irregular
index copies.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">z[gt1]</span> <span class="pre">+=</span> <span class="pre">2.0;</span> <span class="pre">z[~gt1]</span> <span class="pre">-=</span> <span class="pre">2.0</span></code>: two whole-array updates, no
<code class="docutils literal notranslate"><span class="pre">CHUNK</span> <span class="pre">=</span> <span class="pre">4096</span></code> loop, this eliminates floods of tiny copies.</p></li>
</ul>
</section>
</section>
<section id="efficient-multi-gpu-results-4-ranks-1-gpu-each">
<h3>Efficient Multi-GPU Results - (4 Ranks 1 GPU each)<a class="headerlink" href="#efficient-multi-gpu-results-4-ranks-1-gpu-each" title="Link to this heading">#</a></h3>
<p><strong>All ranks:</strong></p>
<a class="reference internal image-reference" href="../_images/gpu_efficient29.png"><img alt="Efficient GPU overview (all ranks)" src="../_images/gpu_efficient29.png" style="width: 90%;" />
</a>
<p><strong>Interpretation:</strong> The profiler is presented as a timeline. The <strong>x-axis</strong> is time, the <strong>y-axis</strong> is organized
by resource/utilization lanes. Each horizontal lane represents a particular resource stream
(CPU workers, GPU Device/Host, runtime/Utility threads, memory pools like Framebuffer/Zerocopy,
and copy/Channel). Colored boxes show work on that resource; the box width is how long it ran,
gaps indicate idle/waiting, and dense barcode slivers usually mean many tiny tasks (high overhead),
while long solid blocks indicate fewer, larger tasks (better utilization).</p>
<section id="id15">
<h4>GPU Dev<a class="headerlink" href="#id15" title="Link to this heading">#</a></h4>
<a class="reference internal image-reference" href="../_images/gpuDev_efficient30.png"><img alt="Efficient GPU device average utilization" src="../_images/gpuDev_efficient30.png" style="width: 90%;" />
</a>
<p><strong>Why this is good:</strong></p>
<p>Steady compute time: The green avg line goes high and stays high while work
runs. That means the GPU is busy doing math, not waiting around. Few, wide
kernels: Solid, thick bars mean big kernels that do lots of work per launch
(less start/stop overhead). Gaps between kernels are short, showing good
overlap with transfers and low idle time. Device time is spent on real
computation (vector add, masked overwrite, threshold updates) instead of
launch/sync overhead.</p>
<p>Efficient Code:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">np.add(x,</span> <span class="pre">y,</span> <span class="pre">out=z)</span></code>: launches a single wide vector add kernel, not
build+copy+separate add.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">np.putmask(z,</span> <span class="pre">cond,</span> <span class="pre">x*y</span> <span class="pre">+</span> <span class="pre">1.0)</span></code>: compiles to one masked overwrite
kernel; avoids scatter that would fragment into many micro-kernels.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">z[gt1]</span> <span class="pre">+=</span> <span class="pre">2.0;</span> <span class="pre">z[~gt1]</span> <span class="pre">-=</span> <span class="pre">2.0</span></code>: just two whole-array updates, not
thousands of <code class="docutils literal notranslate"><span class="pre">CHUNK</span> <span class="pre">=</span> <span class="pre">4096</span></code> slice updates.</p></li>
</ul>
</section>
<section id="id16">
<h4>GPU Host<a class="headerlink" href="#id16" title="Link to this heading">#</a></h4>
<a class="reference internal image-reference" href="../_images/gpuHost_efficient31.png"><img alt="Efficient GPU host average utilization" src="../_images/gpuHost_efficient31.png" style="width: 90%;" />
</a>
<p><strong>Why this is good:</strong></p>
<p>Mostly quiet baseline with a few short bursts aligned to device kernels
showing minimal launch/orchestration overhead. Avg line stays low between
bursts; no comb/barcode pattern of micro-launches. The host is mostly idle
while the GPU runs long kernels, which is exactly what you want. Clear
separation of roles: CPU briefly issues work; GPU does the heavy lifting.</p>
<p>Efficient Code:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">np.add(x,</span> <span class="pre">y,</span> <span class="pre">out=z)</span></code>: one large launch, not build+copy+extra kernel.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">np.putmask(z,</span> <span class="pre">cond,</span> <span class="pre">x*y</span> <span class="pre">+</span> <span class="pre">1.0)</span></code>: mask update (no scatter/nonzero),
avoiding extra setup and multiple small launches.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">z[gt1]</span> <span class="pre">+=</span> <span class="pre">2.0;</span> <span class="pre">z[~gt1]</span> <span class="pre">-=</span> <span class="pre">2.0</span></code>: just two whole-array updates, no
<code class="docutils literal notranslate"><span class="pre">CHUNK</span> <span class="pre">=</span> <span class="pre">4096</span></code> loop means orders of magnitude fewer launches.</p></li>
</ul>
</section>
<section id="id17">
<h4>Framebuffer<a class="headerlink" href="#id17" title="Link to this heading">#</a></h4>
<a class="reference internal image-reference" href="../_images/fb_efficient32.png"><img alt="Efficient framebuffer average utilization" src="../_images/fb_efficient32.png" style="width: 90%;" />
</a>
<p><strong>Why this is good:</strong></p>
<p>Low flat line that stays at ~0% utilization most the run then gradually builds
up to ~1% utilization at the end, showing memory management isnt a bottleneck.
Alloc/teardown bumps are short; theres no mid-run allocation mess, so data
lives in device memory while kernels run.</p>
<p>Efficient Code:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">np.add(x,</span> <span class="pre">y,</span> <span class="pre">out=z)</span></code>: writes into a preallocated output (no extra
full-size temporary to allocate/free).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">np.putmask(z,</span> <span class="pre">cond,</span> <span class="pre">x*y</span> <span class="pre">+</span> <span class="pre">1.0)</span></code>: mask update, not scatter (avoids
partitioned/irregular storage and extra instances).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">z[gt1]</span> <span class="pre">+=</span> <span class="pre">2.0;</span> <span class="pre">z[~gt1]</span> <span class="pre">-=</span> <span class="pre">2.0</span></code>: two whole-array passes, no
<code class="docutils literal notranslate"><span class="pre">CHUNK</span> <span class="pre">=</span> <span class="pre">4096</span></code> loop (prevents thousands of small ephemeral instances).</p></li>
</ul>
</section>
<section id="id18">
<h4>Zerocopy<a class="headerlink" href="#id18" title="Link to this heading">#</a></h4>
<a class="reference internal image-reference" href="../_images/zc_efficient33.png"><img alt="Efficient Zerocopy average utilization" src="../_images/zc_efficient33.png" style="width: 90%;" />
</a>
<p><strong>Why this is good:</strong></p>
<p>Avg stays at ~0% utilization for the entire run, Zerocopy traffic is
negligible. Only a few short alloc/free ticks near the end; no background
chatter. No measurable Zerocopy activity. That means that Zerocopy wasnt used
for steady data movement. Instead, data was staged in device memory and moved
through the normal Channel (DMA) path, with no measurable reliance on pinned
host memory.</p>
<p>Efficient Code:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">np.add(x,</span> <span class="pre">y,</span> <span class="pre">out=z)</span></code>: computes in-place into a preallocated device array,
avoiding extra host to device touches.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">np.putmask(z,</span> <span class="pre">cond,</span> <span class="pre">x*y</span> <span class="pre">+</span> <span class="pre">1.0)</span></code>: mask update (no <code class="docutils literal notranslate"><span class="pre">nonzero</span> <span class="pre">+</span> <span class="pre">scatter</span></code>),
preventing irregular host-pinned traffic.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">z[gt1]</span> <span class="pre">+=</span> <span class="pre">2.0;</span> <span class="pre">z[~gt1]</span> <span class="pre">-=</span> <span class="pre">2.0</span></code>: two whole-array kernels (no CHUNK loop),
so there arent many tiny host-access events to begin with.</p></li>
</ul>
</section>
</section>
</section>
<section id="profilers-wrap-up">
<h2>Profilers - Wrap Up<a class="headerlink" href="#profilers-wrap-up" title="Link to this heading">#</a></h2>
<p>By using Legates built-in profiler, you gain the ability to uncover hidden
bottlenecks and inefficiencies in your code. Profiling doesnt just expose
bugs, it provides a lens to reason about performance and systematically
improve it. What looks like small structural tweaks (fusing operations,
avoiding scatter writes, and cutting temporaries), translates into fewer
tasks, less orchestration, and higher throughput. This results in a clear
transition between average code that just runs to efficient, scalable, and
production-ready code. Profiling turns performance tuning from guesswork into
an intentional, data-driven process that elevates code quality from functional
to excellent.</p>
<p>One of the most powerful features is that the view is traceable across resources.
You can click a task in one panel (e.g., GPU Dev) and use its task identifier
(or other metadata) to search and locate the same operation elsewhere. For example,
in Utility to see when it was mapped/launched, or in Channel to see whether data
movement occurred around it. This interactive cross-panel follow the task workflow
makes it much easier to connect a performance symptom (GPU idle time, dense micro-tasks,
unexpected transfers) back to the runtime activity and operations that caused it.
The search also supports multiple keys (not only task IDs), which helps quickly group
and investigate related work.</p>
</section>
<section id="understanding-and-handling-out-of-memory-oom-issues-example-2">
<h2>Understanding and Handling Out-of-Memory (OOM) Issues  Example 2<a class="headerlink" href="#understanding-and-handling-out-of-memory-oom-issues-example-2" title="Link to this heading">#</a></h2>
<section id="how-oom-occurs">
<h3>How OOM Occurs<a class="headerlink" href="#how-oom-occurs" title="Link to this heading">#</a></h3>
<p>cuPyNumeric runs on top of Legate Core. At launch, the <code class="docutils literal notranslate"><span class="pre">legate</span></code> launcher
auto-sizes memory pools for each memory kind it detects (e.g., CPU
<code class="docutils literal notranslate"><span class="pre">SYSTEM_MEM</span></code>, and GPU framebuffer) on the assigned process/GPU. You can
override these defaults to fixed sizes if needed with flags such as
<code class="docutils literal notranslate"><span class="pre">--sysmem</span></code> (MiB of host DRAM) and <code class="docutils literal notranslate"><span class="pre">--fbmem</span></code> (MiB of GPU memory). If an
operation needs to create a new instance that exceeds the reserved capacity of
a pool, the runtime raises an out-of-memory error for that memory kind (e.g.,
<code class="docutils literal notranslate"><span class="pre">SYSTEM_MEM</span></code> or <code class="docutils literal notranslate"><span class="pre">FBMEM</span></code>) and reports the task/store that triggered it.</p>
<p><strong>Why this matters:</strong> Most mystery OOMs arent total node exhaustion, theyre
per-process, per-kind pool exhaustion. The fix is often to:</p>
<ol class="arabic simple">
<li><p>Right-size those pools.</p></li>
<li><p>Reduce peak live instances so they fit.</p></li>
</ol>
</section>
<section id="demo-script">
<h3>Demo Script<a class="headerlink" href="#demo-script" title="Link to this heading">#</a></h3>
<p>Well intentionally run with a tiny <code class="docutils literal notranslate"><span class="pre">SYSTEM_MEM</span></code> pool to trigger a controlled
OOM.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">cupynumeric</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># allocation site, not instantiated yet</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,))</span>

<span class="c1"># allocation site, not instantiated yet</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">,))</span>

<span class="c1"># use only a slice of b; causes b#1</span>
<span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span>

<span class="c1"># use full b; causes instance b#2</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">b</span> <span class="o">+</span> <span class="mi">2</span>

<span class="c1"># will fail</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="mi">3</span>
</pre></div>
</div>
</section>
<section id="cpu-only-run-deterministic-oom">
<h3>CPU-only run (deterministic OOM)<a class="headerlink" href="#cpu-only-run-deterministic-oom" title="Link to this heading">#</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># LEGATE_TEST=1: verbose allocation diagnostics</span>
<span class="nv">LEGATE_TEST</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>legate<span class="w"> </span>--cpus<span class="w"> </span><span class="m">1</span><span class="w"> </span>--gpus<span class="w"> </span><span class="m">0</span><span class="w"> </span>--sysmem<span class="w"> </span><span class="m">40</span><span class="w"> </span>--provenance<span class="w"> </span>oom.py
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">LEGATE_TEST=1</span></code> enables diagnostic/verbose mode: detailed allocation
information such as logical store creation, instance sizes, and memory
reservations, as opposed to a brief undescriptive error message.</p>
<p><code class="docutils literal notranslate"><span class="pre">--provenance</span></code> tells Legate/Legion to record call provenance. From <code class="docutils literal notranslate"><span class="pre">25.11</span></code> onward, this flag (or <code class="docutils literal notranslate"><span class="pre">--profile</span></code>) is required to get the <code class="docutils literal notranslate"><span class="pre">[/path/to/file.py:LINE]</span></code> locations in OOM messages and traces. Enabling call provenance will cause stack trace information to be included in Legion profiles, progress output, nvtx ranges, and some error messages. Without provenance enabled, youll still see the task name and memory kind, but not the exact Python source location.</p>
<p><code class="docutils literal notranslate"><span class="pre">legate</span> <span class="pre">--cpus</span> <span class="pre">1</span> <span class="pre">--gpus</span> <span class="pre">0</span> <span class="pre">--sysmem</span> <span class="pre">40</span> <span class="pre">oom.py</span></code> runs the script <code class="docutils literal notranslate"><span class="pre">oom.py</span></code>
with one CPU worker and a fixed system memory pool of 40 MiB. Legate will
pre-allocate a 40 MiB region from host DRAM to use for all CPU-side array
instances (<code class="docutils literal notranslate"><span class="pre">SYSTEM_MEM</span></code>). Any time an operation requires more than this
reserved pool, youll see a <code class="docutils literal notranslate"><span class="pre">Failed</span> <span class="pre">to</span> <span class="pre">allocate</span> <span class="pre">of</span> <span class="pre">kind</span> <span class="pre">SYSTEM_MEM</span></code> error.</p>
</section>
<section id="gpu-run-fbmem-behavior">
<h3>GPU run (FBMEM behavior)<a class="headerlink" href="#gpu-run-fbmem-behavior" title="Link to this heading">#</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Single GPU, intentionally tight framebuffer pool</span>
<span class="nv">LEGATE_TEST</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>legate<span class="w"> </span>--cpus<span class="w"> </span><span class="m">2</span><span class="w"> </span>--gpus<span class="w"> </span><span class="m">1</span><span class="w"> </span>--fbmem<span class="w"> </span><span class="m">40</span><span class="w"> </span>--sysmem<span class="w"> </span><span class="m">512</span><span class="w"> </span>--provenance<span class="w"> </span>oom.py
</pre></div>
</div>
<p>Tip: Flags are per process. If you use multiple ranks per node, each rank needs
its own slice of <code class="docutils literal notranslate"><span class="pre">--sysmem</span></code> / <code class="docutils literal notranslate"><span class="pre">--fbmem</span></code>.</p>
</section>
</section>
<section id="steps-to-diagnose-oom">
<h2>Steps to Diagnose OOM<a class="headerlink" href="#steps-to-diagnose-oom" title="Link to this heading">#</a></h2>
<section id="step-1-read-the-oom-line">
<h3>Step 1. Read The OOM Line<a class="headerlink" href="#step-1-read-the-oom-line" title="Link to this heading">#</a></h3>
<p>When an OOM happens, the failure line will tell you the memory kind that ran
out (e.g., of kind <code class="docutils literal notranslate"><span class="pre">SYSTEM_MEM</span></code> or GPU framebuffer) and which task/logical
store was being created when it failed. That points you at the operation that
spiked usage.</p>
<p>OOM Error Message (CPU example):</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Failed to allocate 8388608 bytes on memory 1e00000000000000 (of kind SYSTEM_MEM) for region requirement(s) {1} of Task cupynumeric::BinaryOpTask[/home/USER/d/cupynumeric/oom.py:16] (UID 8)
corresponding to a LogicalStore allocated at /home/USER/d/cupynumeric/oom.py:16 There is not enough space because Legate is reserving 33554400 of the available 41943040 bytes for the following LogicalStores:
LogicalStore allocated at /home/USER/d/cupynumeric/oom.py:13:
  Instance 4000000000000003 of size 8388608 covering elements &lt;0&gt;..&lt;1048575&gt;
      created for an operation launched at /home/USER/d/cupynumeric/oom.py:13
LogicalStore allocated at /home/USER/d/cupynumeric/oom.py:7:
  Instance 4000000000000002 of size 8388608 covering elements &lt;0&gt;..&lt;1048575&gt;
      created for an operation launched at /home/USER/d/cupynumeric/oom.py:13
  Instance 4000000000000001 of size 8388592 covering elements &lt;1&gt;..&lt;1048574&gt;
      created for an operation launched at /home/USER/d/cupynumeric/oom.py:10
LogicalStore allocated at /home/USER/d/cupynumeric/oom.py:4:
  Instance 4000000000000000 of size 8388592 covering elements &lt;0&gt;..&lt;1048573&gt;
      created for an operation launched at /home/USER/d/cupynumeric/oom.py:10
</pre></div>
</div>
<section id="decode-error-message">
<h4>Decode Error Message:<a class="headerlink" href="#decode-error-message" title="Link to this heading">#</a></h4>
<p>Important failure line:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Failed to allocate 8388608 bytes on memory 1e00000000000000 (of kind SYSTEM_MEM) for region requirement(s) {1} of Task cupynumeric::BinaryOpTask[/home/USER/d/cupynumeric/oom.py:16] (UID 8)
</pre></div>
</div>
<p>Interpretation: Legate attempted to allocate an 8 MiB array in the 40 MiB
<code class="docutils literal notranslate"><span class="pre">SYSTEM_MEM</span></code> pool for the <code class="docutils literal notranslate"><span class="pre">BinaryOpTask</span></code> at line 16, but no contiguous
free block was available. The OOM originates from that task.</p>
<section id="segment">
<h5>Segment<a class="headerlink" href="#segment" title="Link to this heading">#</a></h5>
<ul>
<li><p>Failed to allocate 8388608 bytes</p>
<p>The runtime tried allocating ~8 MiB for a new array instance. This is the
size of the region (number of elements * element size).</p>
</li>
<li><p>on memory 1e00000000000000 (of kind SYSTEM_MEM)</p>
<p>Internal ID of the memory pool; every memory kind (<code class="docutils literal notranslate"><span class="pre">SYSTEM_MEM</span></code>, <code class="docutils literal notranslate"><span class="pre">FBMEM</span></code>,
<code class="docutils literal notranslate"><span class="pre">ZCMEM</span></code>) has a unique 64-bit handle. <code class="docutils literal notranslate"><span class="pre">(of</span> <span class="pre">kind</span> <span class="pre">..)</span></code> tells you which
memory pool failed, here, system memory (CPU DRAM). If it said <code class="docutils literal notranslate"><span class="pre">FBMEM</span></code>, it
would be GPU framebuffer memory.</p>
</li>
<li><p>for region requirement(s) {1}</p>
<p>Internal bookkeeping number identifying which logical region of the task
requested the allocation.</p>
</li>
<li><p>of Task cupynumeric::BinaryOpTask[/home/USER/d/cupynumeric/oom.py:16] (UID 8)</p>
<p>The task name that triggered the allocation. <code class="docutils literal notranslate"><span class="pre">BinaryOpTask</span></code> corresponds to
a basic elementwise operation in cuPyNumeric (e.g., addition, subtraction).
<code class="docutils literal notranslate"><span class="pre">[/home/USER/:16]</span></code> is the exact source line that triggered the failed
operation (<code class="docutils literal notranslate"><span class="pre">d</span> <span class="pre">=</span> <span class="pre">c</span> <span class="pre">+</span> <span class="pre">3</span></code>) in the demo (e.g., <code class="docutils literal notranslate"><span class="pre">{&quot;file&quot;:</span>
<span class="pre">&quot;/home/USER/d/cupynumeric/oom.py&quot;,</span> <span class="pre">&quot;line&quot;:</span> <span class="pre">16}</span></code>). <code class="docutils literal notranslate"><span class="pre">UID</span></code> is a unique ID
assigned to this particular task invocation by the runtime, it is useful
when correlating with profiler traces.</p>
</li>
</ul>
</section>
</section>
<section id="rest-of-oom-error-message">
<h4>Rest of OOM Error Message<a class="headerlink" href="#rest-of-oom-error-message" title="Link to this heading">#</a></h4>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>corresponding to a LogicalStore allocated at /home/USER/d/cupynumeric/oom.py:16 There is not enough space because Legate is reserving 33554400 of the available 41943040 bytes for the following LogicalStores:
LogicalStore allocated at /home/USER/d/cupynumeric/oom.py:13:
  Instance 4000000000000003 of size 8388608 covering elements &lt;0&gt;..&lt;1048575&gt;
      created for an operation launched at /home/USER/d/cupynumeric/oom.py:13
LogicalStore allocated at /home/USER/d/cupynumeric/oom.py:7:
  Instance 4000000000000002 of size 8388608 covering elements &lt;0&gt;..&lt;1048575&gt;
      created for an operation launched at /home/USER/d/cupynumeric/oom.py:13
  Instance 4000000000000001 of size 8388592 covering elements &lt;1&gt;..&lt;1048574&gt;
      created for an operation launched at /home/USER/d/cupynumeric/oom.py:10
LogicalStore allocated at /home/USER/d/cupynumeric/oom.py:4:
  Instance 4000000000000000 of size 8388592 covering elements &lt;0&gt;..&lt;1048573&gt;
      created for an operation launched at /home/USER/d/cupynumeric/oom.py:10
</pre></div>
</div>
<section id="rest-of-oom-error-message-meaning">
<h5>Rest of OOM Error Message  Meaning<a class="headerlink" href="#rest-of-oom-error-message-meaning" title="Link to this heading">#</a></h5>
<ul>
<li><p>corresponding to a LogicalStore allocated at /home/USER/d/cupynumeric/oom.py:16</p>
<p>A <code class="docutils literal notranslate"><span class="pre">LogicalStore</span></code> is Legates internal representation of an array region
(or view) that lives somewhere in memory. This line confirms that the
store associated with <code class="docutils literal notranslate"><span class="pre">oom.py:16</span></code> (<code class="docutils literal notranslate"><span class="pre">d</span> <span class="pre">=</span> <span class="pre">c</span> <span class="pre">+</span> <span class="pre">3</span></code>) is the one that failed.
The runtime attempted to map that store to physical memory but couldnt
satisfy the allocation.</p>
<p>Note: You can now pinpoint the failure to a specific variable (the result of
<code class="docutils literal notranslate"><span class="pre">d</span> <span class="pre">=</span> <span class="pre">c</span> <span class="pre">+</span> <span class="pre">3</span></code>) and know it wasnt an earlier array but a new instance being
materialized.</p>
</li>
<li><p>There is not enough space because Legate is reserving 33554400 of the available 41943040 bytes for the following LogicalStores:</p>
<p><code class="docutils literal notranslate"><span class="pre">41943040</span></code> bytes - Total reserved pool size for <code class="docutils literal notranslate"><span class="pre">SYSTEM_MEM</span></code>  40 MiB
(<code class="docutils literal notranslate"><span class="pre">--sysmem</span> <span class="pre">40</span></code>).</p>
<p><code class="docutils literal notranslate"><span class="pre">33554400</span></code> bytes - Amount already reserved/consumed by existing instances
(about 32 MiB/Mebibyte).</p>
<p>Note: Out of the 40 MiB pool, roughly 32 MiB is occupied by other arrays.
The remaining ~8 MiB isnt a free, contiguous block large enough to hold a
new instance once alignment and headers are included, and the mapper keeps
currently mapped instances reserved (non-evictable) while creating the next
one. See Overview below for more information.</p>
</li>
<li><p>LogicalStore allocated at /home/USER/d/cupynumeric/oom.py:13:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Instance 4000000000000003 of size 8388608 covering elements &lt;0&gt;..&lt;1048575&gt;
    created for an operation launched at /home/USER/d/cupynumeric/oom.py:13
</pre></div>
</div>
<p>From this line, details where the allocated memories go.
<code class="docutils literal notranslate"><span class="pre">oom.py:13</span> <span class="pre">=</span> <span class="pre">c</span> <span class="pre">=</span> <span class="pre">b</span> <span class="pre">+</span> <span class="pre">2</span></code></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Instance</span> <span class="pre">4000000000000003</span></code> - Internal instance ID. Used internally for
tracking physical allocations.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">size</span> <span class="pre">8388608</span></code> - 8 MiB allocated</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">covering</span> <span class="pre">elements</span> <span class="pre">&lt;0&gt;..&lt;1048575&gt;</span></code> - Range of local elements this
instance covers, 1 million elements (0  1,048,575).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">created</span> <span class="pre">for</span> <span class="pre">an</span> <span class="pre">operation</span> <span class="pre">launched</span> <span class="pre">at</span></code> - Confirms which operation
produced this instance (line 13).</p></li>
</ul>
</li>
<li><p>LogicalStore allocated at /home/USER/d/cupynumeric/oom.py:7:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Instance 4000000000000002 of size 8388608  covering elements &lt;0&gt;..&lt;1048575&gt;
    created for an operation launched at /home/USER/d/cupynumeric/oom.py:13
Instance 4000000000000001 of size 8388592 covering elements &lt;1&gt;..&lt;1048574&gt;
    created for an operation launched at /home/USER/d/cupynumeric/oom.py:10
</pre></div>
</div>
<p>Line 7 corresponds to <code class="docutils literal notranslate"><span class="pre">b</span> <span class="pre">=</span> <span class="pre">np.zeros(...)</span></code>.</p>
<p>Because <code class="docutils literal notranslate"><span class="pre">b</span></code> was sliced (<code class="docutils literal notranslate"><span class="pre">b[1:-1]</span> <span class="pre">=</span> <span class="pre">a</span></code>) and reused (<code class="docutils literal notranslate"><span class="pre">c</span> <span class="pre">=</span> <span class="pre">b</span> <span class="pre">+</span> <span class="pre">2</span></code>),
multiple physical instances exist for the same logical store <code class="docutils literal notranslate"><span class="pre">b</span></code>. Each
instance (~8MiB) represents a materialized subregion or copy created by
different downstream operations. <code class="docutils literal notranslate"><span class="pre">/home/USER/d/cupynumeric/oom.py:10</span> <span class="pre"></span>
<span class="pre">b[1:-1]</span> <span class="pre">=</span> <span class="pre">a</span></code> This slice assignment materializes instances for both <code class="docutils literal notranslate"><span class="pre">a</span></code>
and the sliced view of <code class="docutils literal notranslate"><span class="pre">b</span></code>. Thats why you see instances tied to line 10
for the stores at lines 4 (<code class="docutils literal notranslate"><span class="pre">a</span></code>) and 7 (<code class="docutils literal notranslate"><span class="pre">b</span></code>) in the OOM list. Those
instances stay reserved while later ops run, which is what tightens the
pool and makes the <code class="docutils literal notranslate"><span class="pre">d</span> <span class="pre">=</span> <span class="pre">c</span> <span class="pre">+</span> <span class="pre">3</span></code> allocation at line 16 fail.</p>
</li>
<li><p>LogicalStore allocated at /home/USER/d/cupynumeric/oom.py:4:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Instance 4000000000000000 of size 8388592 covering elements &lt;0&gt;..&lt;1048573&gt;
    created for an operation launched at /home/USER/d/cupynumeric/oom.py:10
</pre></div>
</div>
<p>Line 4 is <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">=</span> <span class="pre">np.ones(...)</span></code>.
<code class="docutils literal notranslate"><span class="pre">a</span></code> remains in memory as an 8 MB instance used earlier by slice assignments.</p>
<p>Note: <code class="docutils literal notranslate"><span class="pre">a</span></code>s memory allocation still exists in the runtime even though its
not directly used later, it hasnt been freed because its referenced by
<code class="docutils literal notranslate"><span class="pre">b[1:-1]</span> <span class="pre">=</span> <span class="pre">a</span></code>.</p>
</li>
</ul>
</section>
</section>
<section id="id19">
<h4>Overview<a class="headerlink" href="#id19" title="Link to this heading">#</a></h4>
<p>The pool reaches capacity because older arrays (<code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>, <code class="docutils literal notranslate"><span class="pre">c</span></code>) memory
allocations still exist in the runtime and havent been released or reclaimed
yet. The new result for <code class="docutils literal notranslate"><span class="pre">d</span> <span class="pre">=</span> <span class="pre">c</span> <span class="pre">+</span> <span class="pre">3</span></code> cant fit at the moment. The why is a
mix of pool size and live instances the program keeps around. From the above
descriptions, we can see that previous arrays and allocations take up ~32MiB
out of the reserved pool of 40MiB.</p>
<ul class="simple">
<li><p>Pool size (<code class="docutils literal notranslate"><span class="pre">SYSTEM_MEM</span></code>): 40 MiB = 41,943,040 bytes</p></li>
<li><p>Already Reserved: 33,554,400 bytes (~32MiB) across four ~8 MiB instances
(<code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> slice/full, <code class="docutils literal notranslate"><span class="pre">c</span></code>).</p></li>
<li><p>Leftover: 41,943,040 - 33,554,400 = 8,388,640 bytes</p></li>
</ul>
<p>The new instance wants 8,388,608 bytes. That looks like it should fit (32 extra
bytes), but it still fails because the runtimes alignment and per-instance
bookkeeping make the actual footprint a bit larger than the printed payload
(8,388,608 bytes). So 32 MiB used + 8 MiB new in a 40 MiB pool can still OOM.
A real instance needs payload + per-instance overhead (e.g., internal instance
header/descriptor and alignment padding managed by Realm/Legion). Even a
modest header (&gt; 64256 bytes, typical for a descriptor + aligned field
layout) pushes the actual requirement to &gt; 8,388,672 bytes, which exceeds the
8,388,640 bytes free. The reserved  for the following LogicalStores list
shows the requested instance sizes (the array field bytes). It doesnt itemize
allocator extras like per-instance headers, layout descriptors, or alignment
padding the Realm/Legion allocator needs to place the instance in that memory.</p>
</section>
</section>
<section id="step-2-verify-resource-reservations">
<h3>Step 2. Verify Resource Reservations<a class="headerlink" href="#step-2-verify-resource-reservations" title="Link to this heading">#</a></h3>
<p>Confirm the runtime actually reserved enough memory for your process(es): use
<code class="docutils literal notranslate"><span class="pre">--show-config</span></code>, and remember that flags are per process. When you run
multiple ranks per node, each process needs its own slice of CPU/GPU memory,
sometimes you may even need to reduce per-rank <code class="docutils literal notranslate"><span class="pre">--sysmem</span></code>/bind CPUs.
<code class="docutils literal notranslate"><span class="pre">--show-config</span></code> is a fast sanity check that explains an OOM is due to
mis-sizing pools per rank.</p>
<ul class="simple">
<li><p>Catches misconfig: Confirms your per-rank
<code class="docutils literal notranslate"><span class="pre">--sysmem</span></code> / <code class="docutils literal notranslate"><span class="pre">--fbmem</span></code> / <code class="docutils literal notranslate"><span class="pre">--zcmem</span></code> are what you think they are.
If too big for the node or for R ranks, youll OOM regardless of code.</p></li>
<li><p>Disambiguates cause: Distinguishes pool too small vs
duplicate instances/overlap. If pools are clearly undersized, resize
first; else, consider prefetching/other mitigation techniques.</p></li>
<li><p>Clarity: Gives a one-line snapshot to paste into bug reports: exact pool
sizes by memory &amp; rank.</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># legate --show-config</span>
<span class="c1"># print the pools you&#39;d use.. &quot;&amp;&amp;&quot; ..then run the repro with verbose OOM info:</span>
legate<span class="w"> </span>--cpus<span class="w"> </span><span class="m">1</span><span class="w"> </span>--gpus<span class="w"> </span><span class="m">0</span><span class="w"> </span>--sysmem<span class="w"> </span><span class="m">40</span><span class="w"> </span>--show-config<span class="w"> </span><span class="se">\</span>
<span class="o">&amp;&amp;</span><span class="w"> </span><span class="nv">LEGATE_TEST</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>legate<span class="w"> </span>--cpus<span class="w"> </span><span class="m">1</span><span class="w"> </span>--gpus<span class="w"> </span><span class="m">0</span><span class="w"> </span>--sysmem<span class="w"> </span><span class="m">40</span><span class="w"> </span>--provenance<span class="w"> </span>oom.py
</pre></div>
</div>
<p>Confirm the per-kind pool sizes match your flags and that each rank has
sensible values. (If using <code class="docutils literal notranslate"><span class="pre">-n</span></code> or multiple <code class="docutils literal notranslate"><span class="pre">--ranks-per-node</span></code>, scale your
expectations.) An example would look something like:</p>
<p><strong>CPU Run:</strong></p>
<a class="reference internal image-reference" href="../_images/cpu_RPN34.png"><img alt="Example CPU RPN / diagnostic view" src="../_images/cpu_RPN34.png" style="width: 90%;" />
</a>
<p>CUDA_ERROR_NO_DEVICE: Harmless in this context, we asked for
<code class="docutils literal notranslate"><span class="pre">--gpus=0</span></code> so Legion/Realm reports no device and proceeds on CPU only.
Same for ..not able to discover the CUDA resources.</p>
</section>
<section id="step-3-sanity-check-device-memory-externally">
<h3>Step 3. Sanity-Check Device Memory Externally<a class="headerlink" href="#step-3-sanity-check-device-memory-externally" title="Link to this heading">#</a></h3>
<p>On GPU nodes, also glance at <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span></code>, or:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cat<span class="w"> </span>/proc/meminfo<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>MemAvailable
</pre></div>
</div>
<p>to confirm theres headroom/memory on each selected device. If you OOM while
directly allocating memory, check if theres headroom to increase memory
allocation for your run. See visual examples below:</p>
<p>CPU (host RAM):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cat<span class="w"> </span>/proc/meminfo<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>MemAvailable
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/cpu_memavail35.png"><img alt="Example MemAvailable output on CPU" src="../_images/cpu_memavail35.png" style="width: 90%;" />
</a>
<p>GPU (device VRAM):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>nvidia-smi
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/gpu_memavail36.png"><img alt="Example nvidia-smi GPU memory view" src="../_images/gpu_memavail36.png" style="width: 90%;" />
</a>
<ul class="simple">
<li><p>Per-GPU Memory-Usage (1 MiB / 40960 MiB): shows headroom.</p></li>
<li><p>Per-GPU rows (03, A100-SXM4-40GB): Model and count.</p></li>
<li><p>Processes: No running processes found, confirms nothing else is using the
GPUs.</p></li>
</ul>
</section>
</section>
<section id="mitigation-strategies">
<h2>Mitigation Strategies<a class="headerlink" href="#mitigation-strategies" title="Link to this heading">#</a></h2>
<p>Depending on the root cause you analyzed from the OOM message or other
diagnostic technique, there are different mitigations you can take. Parts AD
below will walk you through which mitigation technique to use and when. Note
that these mitigation strategies are not mutually exclusive, most workloads
benefit from a combination of mitigations rather than a single one.</p>
<section id="a-resize-legates-memory-reservations">
<h3>A. Resize Legates Memory Reservations<a class="headerlink" href="#a-resize-legates-memory-reservations" title="Link to this heading">#</a></h3>
<p>By default, Legate uses all available per-rank memory kinds (<code class="docutils literal notranslate"><span class="pre">SYSTEM_MEM</span></code>,
<code class="docutils literal notranslate"><span class="pre">FBMEM</span></code>, <code class="docutils literal notranslate"><span class="pre">ZCMEM</span></code>) unless you constrain them. In some cases, memory is
already used by other processes, so Legate cannot reserve as much as it wants
and you see an OOM. In this case, use <code class="docutils literal notranslate"><span class="pre">--sysmem</span></code> / <code class="docutils literal notranslate"><span class="pre">--fbmem</span></code> (and
optionally <code class="docutils literal notranslate"><span class="pre">--zcmem</span></code>) to size pools explicitly.</p>
<section id="i-when-to-increase-memory">
<h4>(i) When to increase memory<a class="headerlink" href="#i-when-to-increase-memory" title="Link to this heading">#</a></h4>
<p>Use larger pools when the per-rank working set simply needs more space and the
node/device has headroom. This would be a case where you are explicitly
allocating/constraining memory.</p>
<ul class="simple">
<li><p>OOM cites of kind SYSTEM_MEM / FBMEM, and nvidia-smi/MemAvailable show
free memory.</p></li>
<li><p>You keep multiple large arrays/live instances by design (e.g., prefetching
whole arrays, big intermediates).</p></li>
<li><p>You already minimized temporaries/scatter/tiny tasks, but still run into
pool limits.</p></li>
</ul>
<p>How to increase per-rank reservations: <code class="docutils literal notranslate"><span class="pre">--sysmem</span> <span class="pre">&lt;MiB&gt;</span></code> (host DRAM),
<code class="docutils literal notranslate"><span class="pre">--fbmem</span> <span class="pre">&lt;MiB&gt;</span></code> (GPU VRAM), optionally <code class="docutils literal notranslate"><span class="pre">--zcmem</span> <span class="pre">&lt;MiB&gt;</span></code>.</p>
</section>
<section id="ii-when-to-decrease-memory">
<h4>(ii) When to decrease memory<a class="headerlink" href="#ii-when-to-decrease-memory" title="Link to this heading">#</a></h4>
<p>Shrink pools to fit scheduler limits and leave headroom for other processes,
or to encourage spill to host. This would be a case where Legate is
automatically sizing memory pools.</p>
<ul class="simple">
<li><p>Reservation fails at startup (cant pre-reserve), or youre on shared/MIG
GPUs with tighter per-process caps.</p></li>
<li><p>Many ranks per node: <code class="docutils literal notranslate"><span class="pre">R</span> <span class="pre"></span> <span class="pre">--fbmem</span></code> / <code class="docutils literal notranslate"><span class="pre">R</span> <span class="pre"></span> <span class="pre">--sysmem</span></code> would exceed
device/host capacity.</p></li>
<li><p>You want less VRAM pinned (e.g., prefer host placement/offload) or zero-copy
was oversized for the workload.</p></li>
</ul>
<p>How to decrease per-rank reservations or ranks: (lower)
<code class="docutils literal notranslate"><span class="pre">--fbmem</span> <span class="pre">&lt;MiB&gt;</span></code>, <code class="docutils literal notranslate"><span class="pre">--sysmem</span> <span class="pre">&lt;MiB&gt;</span></code>, and/or <code class="docutils literal notranslate"><span class="pre">--zcmem</span> <span class="pre">&lt;MiB&gt;</span></code>; or reduce
<code class="docutils literal notranslate"><span class="pre">--ranks-per-node</span></code>.</p>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 100.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>Per-rank rule:</strong> Pools are per process, If youre launching multiple processes per node, reduce per-rank         reservations or the number of ranks (<code class="docutils literal notranslate"><span class="pre">--ranks-per-node</span></code>). Your per-rank <code class="docutils literal notranslate"><span class="pre">--fbmem</span></code> must fit under what          the scheduler can give each rank/device.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="b-prefetch-the-data">
<h3>B. Prefetch The Data<a class="headerlink" href="#b-prefetch-the-data" title="Link to this heading">#</a></h3>
<p>Prefetching is an optimization technique that involves fetching data and
loading it into memory before it is requested. By proactively materializing
the data to the target memory, along with the required slice ranges, before
the heavy compute, the runtime avoids creating duplicate physical instances of
the same logical array mid-compute, preventing peak-memory spikes and OOM.</p>
<section id="when-to-use-prefetching">
<h4>When to use Prefetching:<a class="headerlink" href="#when-to-use-prefetching" title="Link to this heading">#</a></h4>
<p>(Example from previous 40 MiB <code class="docutils literal notranslate"><span class="pre">SYSTEM_MEM</span></code> run)</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Legate is reserving 33554400 of the available 41943040 bytes for LogicalStores:
LogicalStore allocated at /home/USER/d/cupynumeric/oom.py:13:
  Instance 4000000000000003 of size 8388608 covering elements &lt;0&gt;..&lt;1048575&gt;
      created for an operation launched at /home/USER/d/cupynumeric/oom.py:13
LogicalStore allocated at /home/USER/d/cupynumeric/oom.py:7:
  Instance 4000000000000002 of size 8388608 covering elements &lt;0&gt;..&lt;1048575&gt;
      created for an operation launched at /home/USER/d/cupynumeric/oom.py:13
  Instance 4000000000000001 of size 8388592 covering elements &lt;1&gt;..&lt;1048574&gt;
      created for an operation launched at /home/USER/d/cupynumeric/oom.py:10
</pre></div>
</div>
<p>Refer to the OOM error log: if the OOM log shows the same <code class="docutils literal notranslate"><span class="pre">LogicalStore</span></code>
being instantiated for overlapping/expanding ranges. For example, the slice
assignment at line 10 creates a <code class="docutils literal notranslate"><span class="pre">b</span></code> instance covering <code class="docutils literal notranslate"><span class="pre">&lt;1&gt;..&lt;1048574&gt;</span></code>;
later, <code class="docutils literal notranslate"><span class="pre">c</span> <span class="pre">=</span> <span class="pre">b</span> <span class="pre">+</span> <span class="pre">2</span></code> at line 13 forces a full-range <code class="docutils literal notranslate"><span class="pre">b</span></code> instance
<code class="docutils literal notranslate"><span class="pre">&lt;0&gt;..&lt;1048575&gt;</span></code> under the <code class="docutils literal notranslate"><span class="pre">b</span></code> store that originated at line 7 (created by
the op at line 13), and a separate full-range result instance for <code class="docutils literal notranslate"><span class="pre">c</span></code> (the
store that originates at line 13). This means the runtime has to allocate a
bigger instance while a smaller one is still live  temporary duplication 
peak spike  OOM. In the profiler, youll see transfers/instance creation
appear inside the thick compute band (bad). After prefetch, they should occur
before the band; the channel/transfer lanes are quiet during kernels.</p>
</section>
<section id="technique-1-cupynumeric-stencil-hint-prefetch-for-stencil-halo-ranges">
<h4>Technique 1 - cuPyNumeric <code class="docutils literal notranslate"><span class="pre">stencil_hint</span></code> (prefetch for stencil/halo ranges)<a class="headerlink" href="#technique-1-cupynumeric-stencil-hint-prefetch-for-stencil-halo-ranges" title="Link to this heading">#</a></h4>
<p>API (cuPyNumeric ndarray method):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">stencil_hint</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">low_offsets</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
        <span class="n">high_offsets</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Inform cuPyNumeric that this array will be used in a stencil computation.</span>

<span class="sd">    This allocates space for ghost elements ahead of time, rather than</span>
<span class="sd">    discovering the full extent incrementally, avoiding intermediate copies.</span>
<span class="sd">    &quot;&quot;&quot;</span>
</pre></div>
</div>
<section id="what-it-does">
<h5>What it does:<a class="headerlink" href="#what-it-does" title="Link to this heading">#</a></h5>
<p>Declares a halo (ghost cells), which is a thin border of extra elements around
each partition that holds copies of neighboring data your stencil will read
(e.g., left/right or N/S/E/W). By specifying <code class="docutils literal notranslate"><span class="pre">low_offsets</span></code>/<code class="docutils literal notranslate"><span class="pre">high_offsets</span></code>,
cuPyNumeric materializes one larger backing instance up front that already
includes this halo, rather than discovering the full extent incrementally.
This avoids intermediate copies and mid-compute growth (small instances
growing to large instances), reducing peak memory spikes and helping prevent
OOMs.</p>
</section>
<section id="parameters">
<h5>Parameters:<a class="headerlink" href="#parameters" title="Link to this heading">#</a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">low_offsets</span></code>: per-dimension halo toward the negative direction. Negative
direction refers toward smaller indices on that axis.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">high_offsets</span></code>: per-dimension halo toward the positive direction. Positive
direction refers toward larger indices on that axis.</p></li>
</ul>
<p>Examples:</p>
<ul class="simple">
<li><p>1D: <code class="docutils literal notranslate"><span class="pre">low_offsets=(1,),</span> <span class="pre">high_offsets=(2,)</span></code>  pre-allocate room for neighbors
<code class="docutils literal notranslate"><span class="pre">i-1</span></code> (one to the left) and <code class="docutils literal notranslate"><span class="pre">i+1</span></code>, <code class="docutils literal notranslate"><span class="pre">i+2</span></code> (two to the right).</p></li>
<li><p>2D (shape <code class="docutils literal notranslate"><span class="pre">[rows,</span> <span class="pre">cols]</span></code>): <code class="docutils literal notranslate"><span class="pre">low_offsets=(1,</span> <span class="pre">2),</span> <span class="pre">high_offsets=(3,</span> <span class="pre">1)</span></code> 
Add halo up 1 row and left 2 cols (negative), and down 3 rows and right 1
col (positive).</p></li>
</ul>
<p>Note: Call <code class="docutils literal notranslate"><span class="pre">stencil_hint</span></code> before the stencil section that uses
overlapping/expanding slices. Be slightly conservative: if you might touch up
to 2 cells in a direction, pass 2. Current limitation: behavior may not match
expectations when multiple CPU/OpenMP processors share the same memory.</p>
</section>
<section id="example-1d">
<h5>Example: 1D<a class="headerlink" href="#example-1d" title="Link to this heading">#</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">cupynumeric</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,),</span>      <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># We will touch b[1:-1] now and later its full range  halo 1 on each side</span>
<span class="n">b</span><span class="o">.</span><span class="n">stencil_hint</span><span class="p">(</span><span class="n">low_offsets</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">high_offsets</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,))</span>

<span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">b</span> <span class="o">+</span> <span class="mi">2</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="mi">3</span>
</pre></div>
</div>
<p>Why this works: Without the hint, the runtime may first create a smaller
instance for a subrange (e.g., <code class="docutils literal notranslate"><span class="pre">b[1:-1]</span></code>) and later a larger one (full
<code class="docutils literal notranslate"><span class="pre">b</span></code>) while the smaller is still live, temporarily doubling the footprint.
<code class="docutils literal notranslate"><span class="pre">stencil_hint</span></code> allocates the larger instance once before compute, so
downstream ops reuse it and no mid-band growth occurs.</p>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 100.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>Note:</strong> This technique, when run in place of our original example with the same memory allocation                <code class="docutils literal notranslate"><span class="pre">LEGATE_TEST=1</span> <span class="pre">legate</span> <span class="pre">--cpus</span> <span class="pre">1</span> <span class="pre">--gpus</span> <span class="pre">0</span> <span class="pre">--sysmem</span> <span class="pre">40</span> <span class="pre">--provenance</span> <span class="pre">oom.py</span></code>, easily passes without an OOM.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="technique-2-cupynumeric-prefetch-via-a-whole-array-touch-no-temporaries">
<h4>Technique 2 - cuPyNumeric Prefetch via a whole-array touch (no temporaries)<a class="headerlink" href="#technique-2-cupynumeric-prefetch-via-a-whole-array-touch-no-temporaries" title="Link to this heading">#</a></h4>
<p>If you decide not to call the cuPyNumeric API or you are unsure which slices
will be touched, stage the entire array once with a no-op ufunc that touches
every element without allocating a new array. This is considered prefetching
because you are materializing before compute:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">cupynumeric</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># GPU: materializes in FB_MEM; CPU-only: materializes in SYSTEM_MEM</span>
<span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>      <span class="c1"># or: np.add(b, 0, out=b)   # or: b *= 1</span>

<span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">b</span> <span class="o">+</span> <span class="mi">2</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="mi">3</span>
</pre></div>
</div>
<p>Why this works: Using <code class="docutils literal notranslate"><span class="pre">out=</span></code> (or in-place) guarantees no second full-size
temporary is created while you prefetch. For NumPy-style ufuncs in
cuPyNumeric (e.g., <code class="docutils literal notranslate"><span class="pre">add</span></code>, <code class="docutils literal notranslate"><span class="pre">multiply</span></code>), passing <code class="docutils literal notranslate"><span class="pre">out=arr</span></code> tells the
runtime to write results directly into <code class="docutils literal notranslate"><span class="pre">arr</span></code>s existing buffer. No new
<code class="docutils literal notranslate"><span class="pre">n</span></code>-element result array is allocated; the kernel reads and writes in place.
The prefetch touch is a no-op math pass that forces materialization on the
target memory. With <code class="docutils literal notranslate"><span class="pre">out=</span></code>, that pass reuses the same storage, so you get
the placement effect without creating a second full-size array. After this,
run your heavy ops; the instance already exists at the needed size, so theres
no mid-band growth.</p>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 100.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>Note:</strong> This technique, when run in place of our original example with the same memory allocation                <code class="docutils literal notranslate"><span class="pre">LEGATE_TEST=1</span> <span class="pre">legate</span> <span class="pre">--cpus</span> <span class="pre">1</span> <span class="pre">--gpus</span> <span class="pre">0</span> <span class="pre">--sysmem</span> <span class="pre">40</span> <span class="pre">--provenance</span> <span class="pre">oom.py</span></code>, easily passes without an OOM.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="c-releasing-memory-between-phases-del-gc-and-allocator-pools">
<h3>C. Releasing Memory Between Phases (del, GC, and allocator pools)<a class="headerlink" href="#c-releasing-memory-between-phases-del-gc-and-allocator-pools" title="Link to this heading">#</a></h3>
<p>Dropping references, collecting garbage, and flushing allocator caches shrinks
the live working set so the next phase has the headroom and is less likely to
hit OOM or suffer from cache-induced slowdowns.</p>
<section id="drop-references">
<h4>1) Drop references:<a class="headerlink" href="#drop-references" title="Link to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">del</span></code> statement in Python deletes a reference to an object. It removes
the binding between a variable name and the object it refers to in the current
namespace. It will only delete the object if there are no other references to
it. <code class="docutils literal notranslate"><span class="pre">del</span></code> does not free memory by itself; it just removes a single
reference. An object is actually freed once no references remain. In CPython
(reference implementation of Python) that usually happens immediately via
reference counting; if there are reference cycles, the garbage collector (GC)
may be needed.</p>
<ul class="simple">
<li><p>Delete all names that point to large objects.</p></li>
<li><p>After <code class="docutils literal notranslate"><span class="pre">del</span></code>, the object may still exist if another variable/container
references it.</p></li>
</ul>
</section>
<section id="run-the-garbage-collector">
<h4>2) Run the garbage collector:<a class="headerlink" href="#run-the-garbage-collector" title="Link to this heading">#</a></h4>
<p>Some objects participate in reference cycles and wont be reclaimed by
refcounts (reference counting) alone. Calling <code class="docutils literal notranslate"><span class="pre">gc.collect()</span></code> forces a cycle
detection pass and frees anything thats unreachable. This can reduce your
live Python heap between phases and reclaim memory by cleaning up objects
that are no longer in use.</p>
</section>
<section id="flush-allocator-pools-if-also-using-cupy">
<h4>3) Flush allocator pools (if also using CuPy):<a class="headerlink" href="#flush-allocator-pools-if-also-using-cupy" title="Link to this heading">#</a></h4>
<p>If your process uses CuPy arrays or kernels alongside cuPyNumeric, CuPys
device/pinned memory pools may hold on to large caches.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">MemoryPool.free_all_blocks()</span></code> releases cached device allocations back to
the CUDA driver.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">PinnedMemoryPool.free_all_blocks()</span></code> releases cached pinned host buffers.</p></li>
</ul>
<p><strong>Note:</strong> This frees library caches, not your Python objects, and it doesnt
change Legates reserved pool sizes (<code class="docutils literal notranslate"><span class="pre">--sysmem</span></code> / <code class="docutils literal notranslate"><span class="pre">--fbmem</span></code> /
<code class="docutils literal notranslate"><span class="pre">--zcmem</span></code>). It just makes more room inside those pools for the next phase.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1) Drop references</span>
<span class="n">big</span> <span class="o">=</span> <span class="kc">None</span>                <span class="c1"># break the reference</span>
<span class="k">if</span> <span class="s1">&#39;big&#39;</span> <span class="ow">in</span> <span class="nb">globals</span><span class="p">():</span> <span class="k">del</span> <span class="n">big</span>
<span class="n">cache</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>             <span class="c1"># if you stored big arrays in dicts/lists/closures</span>

<span class="c1"># 2) Reclaim cyclic garbage</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>
<span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

<span class="c1"># 3) If you used CuPy in this process, flush its pools</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
    <span class="n">cp</span><span class="o">.</span><span class="n">get_default_memory_pool</span><span class="p">()</span><span class="o">.</span><span class="n">free_all_blocks</span><span class="p">()</span>
    <span class="n">cp</span><span class="o">.</span><span class="n">get_default_pinned_memory_pool</span><span class="p">()</span><span class="o">.</span><span class="n">free_all_blocks</span><span class="p">()</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="k">pass</span>  <span class="c1"># CuPy not used/installed, or no pools to flush</span>
</pre></div>
</div>
</section>
</section>
<section id="d-offload-to-cpu-memory">
<h3>D. Offload to CPU Memory<a class="headerlink" href="#d-offload-to-cpu-memory" title="Link to this heading">#</a></h3>
<p>If you went through mitigation strategies AC, all memory is clean, you still
need some data to be in memory, Offloading is a way to release some GPU
memory. Offloading to CPU means the runtime migrates the contents of an
array from GPU device memory to host memory (RAM). The data will be
automatically moved back to the GPU later, if necessary for an operation.</p>
<section id="offloading-with-the-legate-offload-to-api">
<h4>Offloading with the Legate <code class="docutils literal notranslate"><span class="pre">offload_to</span></code> API<a class="headerlink" href="#offloading-with-the-legate-offload-to-api" title="Link to this heading">#</a></h4>
<p>In your Legate build (cuPyNumeric 25.11+), you can use the helper
<code class="docutils literal notranslate"><span class="pre">offload_to</span></code> from <code class="docutils literal notranslate"><span class="pre">legate.core.data_interface</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">cupynumeric</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">legate.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">StoreTarget</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">legate.core.data_interface</span><span class="w"> </span><span class="kn">import</span> <span class="n">offload_to</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Work that builds pressure in FBMEM (on GPU runs)</span>
<span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">b</span> <span class="o">+</span> <span class="mi">2</span>

<span class="c1"># Offload &#39;c&#39; (or any large array you won&#39;t need on GPU immediately) to host RAM:</span>
<span class="n">offload_to</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">StoreTarget</span><span class="o">.</span><span class="n">SYSMEM</span><span class="p">)</span>   <span class="c1"># evicts any GPU copies and keeps only a host copy</span>

<span class="c1"># Continue your pipeline; GPU copies will be re-created only if/when needed</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="mi">3</span>
</pre></div>
</div>
<section id="what-this-does">
<h5>What this does:<a class="headerlink" href="#what-this-does" title="Link to this heading">#</a></h5>
<p><code class="docutils literal notranslate"><span class="pre">offload_to</span></code> copies an array to target memory (e.g., system RAM) and
discards any other copies the runtime holds (e.g., in GPU framebuffer). That
immediately frees VRAM for later GPU work. <code class="docutils literal notranslate"><span class="pre">StoreTarget.SYSMEM</span></code> targets CPU
RAM. Other options include <code class="docutils literal notranslate"><span class="pre">FBMEM</span></code> (GPU VRAM) and <code class="docutils literal notranslate"><span class="pre">ZCMEM</span></code> (pinned host
memory for zero-copy). The call makes the CPU copy exclusive (VRAM copies are
discarded), which is what frees space.</p>
<p><strong>Important:</strong> the runtime doesnt pre-check capacity. If the target memory lacks
space, your program can still fail. Make sure the <code class="docutils literal notranslate"><span class="pre">--sysmem</span></code> is large enough
before offloading.</p>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 100.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>Trade-off:</strong> spilling over to host can save you from OOM but may cost performance if frequent transfers          are needed.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
</section>
<section id="e-if-applicable-coding-practices-to-reduce-peak-memory-indirect-oom-handling">
<h3>E. If Applicable: Coding Practices to Reduce Peak Memory (Indirect OOM handling)<a class="headerlink" href="#e-if-applicable-coding-practices-to-reduce-peak-memory-indirect-oom-handling" title="Link to this heading">#</a></h3>
<p>If mitigation strategies for section AD arent enough and you have access to
the code, you can often avoid OOM by lowering the peak working set (the sum of
all live instances at once). Some examples may include (See Example 1 for more
context):</p>
<ul class="simple">
<li><p>Avoiding large index arrays and scatter writes; prefer boolean mask over
<code class="docutils literal notranslate"><span class="pre">nonzero(...)</span></code> + advanced indexing.</p></li>
<li><p>Avoiding per-slice tiny task loops on big arrays; use whole-array
vectorized operations instead.</p></li>
<li><p>Avoiding unnecessary temporaries; write into preallocated outputs (via
<code class="docutils literal notranslate"><span class="pre">out=</span></code>) instead.</p></li>
</ul>
<p>The Legate Profiler can indirectly assist with an OOM diagnosis by finding
inefficiencies in the code. The crash line names the kind of memory that fails
(<code class="docutils literal notranslate"><span class="pre">SYSTEM_MEM</span></code>/<code class="docutils literal notranslate"><span class="pre">FBMEM</span></code>); the profiler will show the time window just before
the crash where Framebuffer/System utilization ramps and stays high while
Channel/Utility stays active. This points to extra temporaries,
scatter/advanced indexing, per-chunk loops, or host to device back and forth,
that keep too many instances live at once and push the pool over capacity.
Launch profiler with <code class="docutils literal notranslate"><span class="pre">--profile</span></code>, &amp; view the <code class="docutils literal notranslate"><span class="pre">legate_*.prof</span></code> files:</p>
<ul class="simple">
<li><p>Pinpoint the phase that grows memory in the timeline, a rising plateau in
Framebuffer (GPU) or System (host) lanes right before failure marks the
phase that inflated memory.</p></li>
<li><p>Channel (DMA copies): a thin, persistent baseline means constant back and
forth between host and device (often a cause of scatter patterns/advanced
indexing), which can mean tons of small transfers which force more data to
be live at the same time and in more places (host &amp; device duplicates) which
can cause OOM errors.</p></li>
<li><p>Utility: a confetti of meta tasks usually correlates with lots of tiny
operations (per-slice loops) that materialize extra temporaries/instances.</p></li>
</ul>
<p>Last resort: Downcast to a smaller data type to cut memory usage in half
(e.g., <code class="docutils literal notranslate"><span class="pre">float32</span> <span class="pre"></span> <span class="pre">float64</span></code> / <code class="docutils literal notranslate"><span class="pre">float16</span> <span class="pre"></span> <span class="pre">float32</span></code>) when numerically
acceptable. Understand by doing so you reduce overall accuracy and dynamic
range, and some operations may upcast internally or lose stability. This is
normally not recommended as most precisions are set for a reason. Prefer mixed
precision (keep accumulators/reductions in <code class="docutils literal notranslate"><span class="pre">float32</span></code>) if full downcasting is
too risky.</p>
<p>Refer to Example 1  Profiling cuPyNumeric Applications with Legate Profilers
for this section to view examples &amp; visualizations.</p>
</section>
</section>
<section id="a-few-examples-for-applying-different-mitigations">
<h2>A Few Examples For Applying Different Mitigations<a class="headerlink" href="#a-few-examples-for-applying-different-mitigations" title="Link to this heading">#</a></h2>
<p>From our earlier example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">cupynumeric</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># allocation site, not instantiated yet</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,))</span>

<span class="c1"># allocation site, not instantiated yet</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">,))</span>

<span class="c1"># use only a slice of b; causes b#1</span>
<span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span>

<span class="c1"># use full b; causes instance b#2</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">b</span> <span class="o">+</span> <span class="mi">2</span>

<span class="c1"># will fail</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="mi">3</span>
</pre></div>
</div>
<section id="what-was-observed-steps-to-diagnose-oom">
<h3>What was observed (Steps to Diagnose OOM):<a class="headerlink" href="#what-was-observed-steps-to-diagnose-oom" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Step 1 (Read the OOM line): The failure is pool exhaustion, instances from
<code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>, <code class="docutils literal notranslate"><span class="pre">c</span></code> are still live, so <code class="docutils literal notranslate"><span class="pre">d</span> <span class="pre">=</span> <span class="pre">c</span> <span class="pre">+</span> <span class="pre">3</span></code> cant fit in the
reserved pool at that moment.</p></li>
<li><p>Step 2 (Verify Resource Reservations): Pool sizes per rank match flags.</p></li>
<li><p>Step 3 (Sanity-check headroom): Host/GPU still have capacity, so the issue
is the per-process pool and peak live instances, not total node memory.</p></li>
</ul>
</section>
<section id="fix-path-a-resize-per-rank-pools-mitigation-a-resize-legates-memory-reservations">
<h3>Fix Path A: Resize per-rank pools (Mitigation A: Resize Legates Memory Reservations)<a class="headerlink" href="#fix-path-a-resize-per-rank-pools-mitigation-a-resize-legates-memory-reservations" title="Link to this heading">#</a></h3>
<p>Easy and Quick: Give the mapper more headroom in the memory kind that failed,
so the next instance places successfully.</p>
<p>CPU-only (increase <code class="docutils literal notranslate"><span class="pre">SYSTEM_MEM</span></code>):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">LEGATE_TEST</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>legate<span class="w"> </span>--gpus<span class="w"> </span><span class="m">0</span><span class="w"> </span>--cpus<span class="w"> </span><span class="m">1</span><span class="w"> </span>--sysmem<span class="w"> </span><span class="m">128</span><span class="w"> </span>oom.py
</pre></div>
</div>
<p>Single-GPU (tight but sane pools; allow host spill):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">LEGATE_TEST</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>legate<span class="w"> </span>--gpus<span class="w"> </span><span class="m">1</span><span class="w"> </span>--cpus<span class="w"> </span><span class="m">2</span><span class="w"> </span>--fbmem<span class="w"> </span><span class="m">128</span><span class="w"> </span>--sysmem<span class="w"> </span><span class="m">512</span><span class="w"> </span>oom.py
</pre></div>
</div>
<p>Flags are per rank; if you run R ranks per node, ensure <code class="docutils literal notranslate"><span class="pre">R</span> <span class="pre"></span> <span class="pre">--sysmem</span></code> and
<code class="docutils literal notranslate"><span class="pre">R</span> <span class="pre"></span> <span class="pre">--fbmem</span></code> fit real host/GPU capacity (e.g., 2 ranks = 2  128 fbmem =
256 fbmem).</p>
</section>
<section id="fix-path-b-prefetch-using-technique-2-whole-array-touch-mitigation-b-prefetch-the-data">
<h3>Fix Path B: Prefetch Using Technique 2 - Whole Array Touch (Mitigation B: Prefetch the Data)<a class="headerlink" href="#fix-path-b-prefetch-using-technique-2-whole-array-touch-mitigation-b-prefetch-the-data" title="Link to this heading">#</a></h3>
<p>When diagnosing an OOM, and you come across duplicated instances, consider
prefetching. By proactively materializing the data to the target memory, along
with the required slice ranges prior to heavy computation, the runtime avoids
creating duplicated physical instances of the same logical array mid-compute.
This prevents peak-memory spikes and OOM.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">cupynumeric</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># GPU: materializes in FB_MEM; CPU-only: materializes in SYSTEM_MEM</span>
<span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>      <span class="c1"># or: np.add(b, 0, out=b)   # or: b *= 1</span>

<span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">b</span> <span class="o">+</span> <span class="mi">2</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="mi">3</span>
</pre></div>
</div>
<p>Note: In practice, using <code class="docutils literal notranslate"><span class="pre">stencil_hint</span></code> is definitely the preferred and more
principled prefetching strategy. The whole-array touch shown here works for
this simple example, but stencil-based prefetching is generally safer and more
scalable for real workloads where slice ranges and halo regions matter.</p>
</section>
<section id="fix-path-c-reduce-the-live-working-set-mitigation-c-releasing-memory-between-phases-del-gc-and-allocator-pools">
<h3>Fix Path C: Reduce the live working set (Mitigation C: Releasing Memory Between Phases (del, GC, and allocator pools))<a class="headerlink" href="#fix-path-c-reduce-the-live-working-set-mitigation-c-releasing-memory-between-phases-del-gc-and-allocator-pools" title="Link to this heading">#</a></h3>
<p>Shrink peak live instances so the same pool size suffices, no new memory
required. Replace temporaries with in-place ops and drop unneeded references:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">cupynumeric</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span><span class="o">,</span><span class="w"> </span><span class="nn">gc</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">,))</span>

<span class="c1"># stage, then drop &#39;a&#39; to reduce the live set (C.1 + C.2)</span>
<span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span>
<span class="n">a</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

<span class="c1"># avoid creating &#39;c&#39; and &#39;d&#39; instances: in-place updates</span>
<span class="n">np</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>   <span class="c1"># replaces: c = b + 2</span>
<span class="n">np</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>   <span class="c1"># replaces: d = c + 3</span>

<span class="c1"># optional: if CuPy is also in this process, free its caches (C.3)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">cupy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">cp</span>
    <span class="n">cp</span><span class="o">.</span><span class="n">get_default_memory_pool</span><span class="p">()</span><span class="o">.</span><span class="n">free_all_blocks</span><span class="p">()</span>
    <span class="n">cp</span><span class="o">.</span><span class="n">get_default_pinned_memory_pool</span><span class="p">()</span><span class="o">.</span><span class="n">free_all_blocks</span><span class="p">()</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
</div>
</section>
<section id="quick-re-checks-before-rerun-steps-to-diagnose-oom-steps-23">
<h3>Quick re-checks before rerun (Steps to Diagnose OOM: Steps 23):<a class="headerlink" href="#quick-re-checks-before-rerun-steps-to-diagnose-oom-steps-23" title="Link to this heading">#</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>legate<span class="w"> </span>--show-config<span class="w">                  </span><span class="c1"># pools per rank match intent?</span>
cat<span class="w"> </span>/proc/meminfo<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>MemAvailable<span class="w"> </span><span class="c1"># host headroom</span>
nvidia-smi<span class="w">                            </span><span class="c1"># GPU headroom</span>
</pre></div>
</div>
<p>Result: Path A expands the pool; Path B &amp; C lowers peak usage. Either resolves
the example OOM for <code class="docutils literal notranslate"><span class="pre">d</span> <span class="pre">=</span> <span class="pre">c</span> <span class="pre">+</span> <span class="pre">3</span></code> and makes the cause and fix explicit.</p>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 100.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>Important:</strong> These mitigation strategies are being implemented on a very simple example. For more                complex, larger programs, consider also using offloading, on top of or instead of some of these techniques.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            


              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#usage">Usage</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#profiling-cupynumeric-applications-with-legate-profilers-example-1">Profiling cuPyNumeric Applications with Legate Profilers  Example 1</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inefficient-code">Inefficient code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-this-code-works">How this code works</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#array-creation">Array creation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#index-selection-via-nonzero">Index selection via <code class="docutils literal notranslate"><span class="pre">nonzero</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#temporaries">Temporaries</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#scatter-assignment">Scatter assignment</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#tiny-chunk-loop">Tiny-chunk loop</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#profiler-output-and-interpretation-inefficient-cpu-results">Profiler Output and Interpretation - Inefficient CPU Results</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cpu">1) CPU</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#what-this-shows">What this shows</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#cpu-avg">CPU Avg</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#utility">2) Utility</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">What this shows</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#utility-avg">Utility Avg</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#i-o-input-output">3) I/O (input/output)</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">What this shows</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#i-o-avg">I/O Avg</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#system">4) System</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">What this shows</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#channel-chan">5) Channel (chan)</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">What this shows</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#channel-avg">Channel Avg</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dependent-partitioning-dp">6) Dependent Partitioning (dp)</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">What this shows</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation">Interpretation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inefficient-gpu-results-4-ranks-1-gpu-each">Inefficient GPU Results - (4 Ranks 1 GPU each)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpu-dev">1) GPU Dev</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">What this shows</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#gpu-dev-avg">GPU Dev Avg</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpu-host">2) GPU Host</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">What this shows</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#gpu-host-avg">GPU Host Avg</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#zerocopy">3) Zerocopy</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">What this shows</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#framebuffer">4) Framebuffer</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">What this shows</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#efficient-code">Efficient Code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">How this code works</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#array-creation-data-type-copies">Array creation (data type &amp; copies)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#base-computation">Base computation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-overwrite-indices-vs-mask">Conditional overwrite (indices vs mask)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#chunked-loop-vs-vectorized">Chunked loop vs Vectorized</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#profiler-output-and-interpretation-efficient-cpu-results">Profiler Output and Interpretation - Efficient CPU Results</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">CPU</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">Utility</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#i-o">I/O</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">System</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">Channel (chan)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#efficient-multi-gpu-results-4-ranks-1-gpu-each">Efficient Multi-GPU Results - (4 Ranks 1 GPU each)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">GPU Dev</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">GPU Host</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">Framebuffer</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id18">Zerocopy</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#profilers-wrap-up">Profilers - Wrap Up</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-and-handling-out-of-memory-oom-issues-example-2">Understanding and Handling Out-of-Memory (OOM) Issues  Example 2</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-oom-occurs">How OOM Occurs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-script">Demo Script</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cpu-only-run-deterministic-oom">CPU-only run (deterministic OOM)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpu-run-fbmem-behavior">GPU run (FBMEM behavior)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#steps-to-diagnose-oom">Steps to Diagnose OOM</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-read-the-oom-line">Step 1. Read The OOM Line</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#decode-error-message">Decode Error Message:</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#segment">Segment</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#rest-of-oom-error-message">Rest of OOM Error Message</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#rest-of-oom-error-message-meaning">Rest of OOM Error Message  Meaning</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id19">Overview</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-verify-resource-reservations">Step 2. Verify Resource Reservations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-sanity-check-device-memory-externally">Step 3. Sanity-Check Device Memory Externally</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mitigation-strategies">Mitigation Strategies</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-resize-legates-memory-reservations">A. Resize Legates Memory Reservations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#i-when-to-increase-memory">(i) When to increase memory</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ii-when-to-decrease-memory">(ii) When to decrease memory</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-prefetch-the-data">B. Prefetch The Data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#when-to-use-prefetching">When to use Prefetching:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#technique-1-cupynumeric-stencil-hint-prefetch-for-stencil-halo-ranges">Technique 1 - cuPyNumeric <code class="docutils literal notranslate"><span class="pre">stencil_hint</span></code> (prefetch for stencil/halo ranges)</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#what-it-does">What it does:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#parameters">Parameters:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#example-1d">Example: 1D</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#technique-2-cupynumeric-prefetch-via-a-whole-array-touch-no-temporaries">Technique 2 - cuPyNumeric Prefetch via a whole-array touch (no temporaries)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#c-releasing-memory-between-phases-del-gc-and-allocator-pools">C. Releasing Memory Between Phases (del, GC, and allocator pools)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#drop-references">1) Drop references:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-garbage-collector">2) Run the garbage collector:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#flush-allocator-pools-if-also-using-cupy">3) Flush allocator pools (if also using CuPy):</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d-offload-to-cpu-memory">D. Offload to CPU Memory</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#offloading-with-the-legate-offload-to-api">Offloading with the Legate <code class="docutils literal notranslate"><span class="pre">offload_to</span></code> API</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#what-this-does">What this does:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#e-if-applicable-coding-practices-to-reduce-peak-memory-indirect-oom-handling">E. If Applicable: Coding Practices to Reduce Peak Memory (Indirect OOM handling)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-few-examples-for-applying-different-mitigations">A Few Examples For Applying Different Mitigations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-was-observed-steps-to-diagnose-oom">What was observed (Steps to Diagnose OOM):</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fix-path-a-resize-per-rank-pools-mitigation-a-resize-legates-memory-reservations">Fix Path A: Resize per-rank pools (Mitigation A: Resize Legates Memory Reservations)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fix-path-b-prefetch-using-technique-2-whole-array-touch-mitigation-b-prefetch-the-data">Fix Path B: Prefetch Using Technique 2 - Whole Array Touch (Mitigation B: Prefetch the Data)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fix-path-c-reduce-the-live-working-set-mitigation-c-releasing-memory-between-phases-del-gc-and-allocator-pools">Fix Path C: Reduce the live working set (Mitigation C: Releasing Memory Between Phases (del, GC, and allocator pools))</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quick-re-checks-before-rerun-steps-to-diagnose-oom-steps-23">Quick re-checks before rerun (Steps to Diagnose OOM: Steps 23):</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            

          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  

  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>


  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
<a class="footer-brand logo" href="https://www.nvidia.com">
  <img src="../_static/nvidia-logo-horiz-rgb-1c-blk-for-screen.svg" class="logo__image only-light" alt="NVIDIA"/>
  <img src="../_static/nvidia-logo-horiz-rgb-1c-wht-for-screen.svg" class="logo__image only-dark" alt="NVIDIA"/>
</a></div>
      
        <div class="footer-item">

<div class="footer-links">
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/">Privacy Policy</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/">Your Privacy Choices</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/">Terms of Service</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/accessibility/">Accessibility</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/company-policies/">Corporate Policies</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/product-security/">Product Security</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/contact/">Contact</a>
  
  
  
</div>
</div>
      
        <div class="footer-item">




  <p class="copyright">
    
      Copyright  2024, NVIDIA.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
<div class="extra_footer">
  
  The cuPyNumeric project is independent of the CuPy project. CuPy is a trademark of Preferred Networks, Inc, and the name 'cuPyNumeric' is used with their permission.
  
  <script type="text/javascript">if (typeof _satellite !== undefined){ _satellite.pageBottom();}</script>
  
</div></div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>